Homework 6: working with stringr and nested lists
================
Emily West
11/5/2017

Dear Reveiwer,
==============

Welcome to my first STAT 547A homework! I am new to the course, having taken Jenny Bryan's STAT 545 last fall so please bear with me as I warm up some out-of-shape coding muscles. Considering I return to my 545 homework assignments fairly regularly to check specific code and functions I hope to format these homework assignments in much the same way, filled with lots of comments about what works, why it works, and of course what doesn't work and potential reasons for why that is.

PART I:
=======

For the first part of this homework adventure I opted to work through the exercises in the strings chapter of R for data science (before Guilio's public service anouncement on Tues. about not doing the whole thing).

Some background on regular expressions: a regular expression is simply a pattern describing a string of characters. A regular expression is used to match 0-n characters in a string. A regular expression can include digits and letters which will match to themselves. Metacharacters are characters with special meaning including  $ . \[ { etc, to match a metacharacter it must be preceded with a backslash.

############ 14.2.5

1.  paste() is a concatenate function that binds together character strings. You can designate a desired seperate function, such as sep = "," or sep = ".", however the default is sep = " ". The paste0() is similar in its function but instead the default seperation is sep = "", making it more efficient. glue() is a stringr function that is similar to base R's paste(). paste() will return NA's if they are present in tbe vector

``` r
x<-c("abc","ab",NA)
y<-c("xyz", "yz", "z")

(paste(x,y)) #space is default seperator, NA is returned
```

    ## [1] "abc xyz" "ab yz"   "NA z"

``` r
(paste0(x,y)) #space is dropped, NA still returned
```

    ## [1] "abcxyz" "abyz"   "NAz"

``` r
(glue("{x}{y}")) #no spaces, NA still returned
```

    ## abcxyz
    ## abyz
    ## NAz

1.  If you were using str\_c to develop a matrix of strings, the sep = would designate the string to be placed between each column, whereas collapse designates whether or not each row is collapse into a single string or the entire matrix collapsed into a string. collapse = NULL means that each row is a string, collapse = non-NUll, the entire matrix is a single string.

``` r
str_c(y, sep = ".", collapse = NULL) # there are still 3 strings of lengths 3,2,1
```

    ## [1] "xyz" "yz"  "z"

``` r
str_c(y, sep = ".", collapse = ",") # now we have one string of a length 8
```

    ## [1] "xyz,yz,z"

1.  Extract the middle character from a string using str\_subset() and str\_length(): Note: str\_sub(argument, character location to start, character location to end)

``` r
(str_c(y, sep = ".", collapse = NULL)) # there are still 3 strings of lengths 3,2,1
```

    ## [1] "xyz" "yz"  "z"

``` r
str_c(y, sep = ".", collapse = ",") # now we have one string of a length 8
```

    ## [1] "xyz,yz,z"

``` r
x<- "abcd"
(str_length(x)) #tricky, now there is a string with an even number of characters!
```

    ## [1] 4

``` r
str_length(x)/2
```

    ## [1] 2

``` r
(str_sub(x, 2,3)) #now I have selected for the 2 middle characters
```

    ## [1] "bc"

1.  str\_wrap() is a formatting function that formats strings into paragraphs that are designated by the input paramaters

``` r
y <- "R is a challenging language for some of us to learn, however it is proving to be an invaluable tool in expediating and tracking analyses related to my thesis"
str_wrap(y, width = 25, indent = 2) #yikes, this is ugly - \n is showing the placement of each paragraph, 25 indicates that as close to 25 characters should be printed per line 
```

    ## [1] "  R is a challenging\nlanguage for some of\nus to learn, however\nit is proving to be\nan invaluable tool in\nexpediating and tracking\nanalyses related to my\nthesis"

``` r
cat(str_wrap(y, width = 25)) #cat() is a nice way to print the output of the str_wrap to visually check the formatting
```

    ## R is a challenging
    ## language for some of
    ## us to learn, however
    ## it is proving to be
    ## an invaluable tool in
    ## expediating and tracking
    ## analyses related to my
    ## thesis

1.  str\_trim() "trims" the whitespace from the beginning and end of a character string:

``` r
a <- c(" a ", " b ", " a b ")
str_trim(a) #trims the leading and tailing white space but maintains spaces in between characters
```

    ## [1] "a"   "b"   "a b"

1.  Write a function that turns a vector into a string, consider what it should do if a vector length 0,1,2 is input

``` r
c<-c("a", "b", "c")
d<-c("a","b")
str_length(c) #3 strings with a length of 1
```

    ## [1] 1 1 1

``` r
to_str<-function(x){
   if(length(x)<3) {
     stop('I am so sorry, but this function only works for vectors greater than 3 characters')} #vector must have a length longer than 3, again the 
  str_c(x, collapse = "")
  }

#to_str(d) #function fails on a vector with a length shorter than 3!
str_length(to_str(c)) # a single string with a length of 3
```

    ## [1] 3

############ 14.3.1

Matching is all about indicating and locating a character, or set of characters, you are interested in. examples from the text:

``` r
x <- c("apple", "banana", "pear")
str_view(x, "an") 
```

<!--html_preserve-->

<script type="application/json" data-for="htmlwidget-cad46d94ba30fc334c10">{"x":{"html":"<ul>\n  <li>apple<\/li>\n  <li>b<span class='match'>an<\/span>ana<\/li>\n  <li>pear<\/li>\n<\/ul>"},"evals":[],"jsHooks":[]}</script>
<!--/html_preserve-->
``` r
#in x highlight characters a and n, based on the the output from banana and apple, this suggests str_view will not return redundant strings, that is it only highlights the first "p" in apple and the first instance of "an" in banana 
str_view(x, ".a.") 
```

<!--html_preserve-->

<script type="application/json" data-for="htmlwidget-4a247d4252ede8c5180d">{"x":{"html":"<ul>\n  <li>apple<\/li>\n  <li><span class='match'>ban<\/span>ana<\/li>\n  <li>p<span class='match'>ear<\/span><\/li>\n<\/ul>"},"evals":[],"jsHooks":[]}</script>
<!--/html_preserve-->
``` r
#"." before and after a character has a special behavior that matches any character around the character you indicate. If you actually want to match a "." you have to escape it using a backslash
```

1.Explain why each of these strings don’t match a : "", "\\", "\\". A backslash is an extra special character because it has two functions, one used to create regular expressions and the other to escape other special characters like ".", "'" This is best expressed with a couple of examples, note the original code is from the R for Data Science example, however I have modifided and expanded it to make expressly clear what is happening in each step.

``` r
str_view(c("abc", "a.c", "bef"), "a.c")#returns a and c with ANY character in between the two
```

<!--html_preserve-->

<script type="application/json" data-for="htmlwidget-69588a09723b1c51804a">{"x":{"html":"<ul>\n  <li><span class='match'>abc<\/span><\/li>\n  <li><span class='match'>a.c<\/span><\/li>\n  <li>bef<\/li>\n<\/ul>"},"evals":[],"jsHooks":[]}</script>
<!--/html_preserve-->
``` r
str_view(c("abc", "a.c", "bef"), "a\\.c") #returns a.c literally, that is, "." is not being used in its special way of matching any character it is being used as a character itself
```

<!--html_preserve-->

<script type="application/json" data-for="htmlwidget-8b439698971ac3be2be3">{"x":{"html":"<ul>\n  <li>abc<\/li>\n  <li><span class='match'>a.c<\/span><\/li>\n  <li>bef<\/li>\n<\/ul>"},"evals":[],"jsHooks":[]}</script>
<!--/html_preserve-->
``` r
str_view(c("abc", "a.c", "bef"), "\\.") #returns . as its own character
```

<!--html_preserve-->

<script type="application/json" data-for="htmlwidget-0422d64bfb8d7c84b973">{"x":{"html":"<ul>\n  <li>abc<\/li>\n  <li>a<span class='match'>.<\/span>c<\/li>\n  <li>bef<\/li>\n<\/ul>"},"evals":[],"jsHooks":[]}</script>
<!--/html_preserve-->
``` r
# str_view(c("abc", "a\c", "bef"), "\\\\") #Yikes, that won't work because R is looking for a special character to escape after the \
str_view(c("abc", "a\\c", "bef"), "\\\\") # in the string itself we need a \ to escape the backslash and in the parameter we need the double backslash to match the special character \ that is being escaped in the first place.
```

<!--html_preserve-->

<script type="application/json" data-for="htmlwidget-72955348ed29920a7947">{"x":{"html":"<ul>\n  <li>abc<\/li>\n  <li>a<span class='match'>\\<\/span>c<\/li>\n  <li>bef<\/li>\n<\/ul>"},"evals":[],"jsHooks":[]}</script>
<!--/html_preserve-->
2.How would you match the sequence "'? \#This requires escaping a string of special characters, which means everyone gets their own backslash:

``` r
str_view(c("\"\'\\"), "\\'\\\\") 
```

<!--html_preserve-->

<script type="application/json" data-for="htmlwidget-ed1376f16c9eb7e2bbb8">{"x":{"html":"<ul>\n  <li>\"<span class='match'>'\\<\/span><\/li>\n<\/ul>"},"evals":[],"jsHooks":[]}</script>
<!--/html_preserve-->
``` r
#something funny is happening, the quotes are being closed so they are not being matched- I tried several iterations of adding backslashes before the " but to no avail :(
str_view(c("\'\\"), "\\'\\\\") 
```

<!--html_preserve-->

<script type="application/json" data-for="htmlwidget-dde3aee31813a0f783e2">{"x":{"html":"<ul>\n  <li><span class='match'>'\\<\/span><\/li>\n<\/ul>"},"evals":[],"jsHooks":[]}</script>
<!--/html_preserve-->
``` r
#I can get the last two characters to be matched
```

1.  What patterns will the regular expression ...... match? How would you represent it as a string?

``` r
c<- "\asdfghjkl"
#str_view(c, "\..\..\..") # str_view does not seem to like this type of expression because of the \. which is it designating an "unrecognized escape character"
c<- "what if i.write a sentence.with lots of periods.init"
#str_view(c, "\..\..\..") #hmmm the way I read the expression is: escape the "." and match any character after it, but that does not appear so. 
#c<- "what if i\.write a sentence\.with lots of periods.init"
#str_view(c, "\\..\\..\\..") #NOPE
```

############ 14.3.2

Special "anchors": ^ matches the start of a string, $ matches the end of a string Hadley Wickham remembers it this way: "To remember which is which, try this mnemonic which I learned from Evan Misshula: if you begin with power (^), you end up with money ($)."

1.  How would you match the literal string "$^$"?

``` r
str_view(c("$^$"), "\\$\\^\\$") #escape and match all special characters using \\
```

<!--html_preserve-->

<script type="application/json" data-for="htmlwidget-773460790118842fca94">{"x":{"html":"<ul>\n  <li><span class='match'>$^$<\/span><\/li>\n<\/ul>"},"evals":[],"jsHooks":[]}</script>
<!--/html_preserve-->
1.  Given the corpus of common words in stringr::words, create regular expressions that find all words that: First, what are we dealing with in stringr::words? View(stringr::words), wow 980 words!

<!-- -->

1.  Start with y:

``` r
str_view(stringr::words, "^y", match = TRUE)
```

<!--html_preserve-->

<script type="application/json" data-for="htmlwidget-445025b73b7890e6d4de">{"x":{"html":"<ul>\n  <li><span class='match'>y<\/span>ear<\/li>\n  <li><span class='match'>y<\/span>es<\/li>\n  <li><span class='match'>y<\/span>esterday<\/li>\n  <li><span class='match'>y<\/span>et<\/li>\n  <li><span class='match'>y<\/span>ou<\/li>\n  <li><span class='match'>y<\/span>oung<\/li>\n<\/ul>"},"evals":[],"jsHooks":[]}</script>
<!--/html_preserve-->
1.  End with x:

``` r
str_view(stringr::words, "x$", match = TRUE)
```

<!--html_preserve-->

<script type="application/json" data-for="htmlwidget-828ab00874e5c6504406">{"x":{"html":"<ul>\n  <li>bo<span class='match'>x<\/span><\/li>\n  <li>se<span class='match'>x<\/span><\/li>\n  <li>si<span class='match'>x<\/span><\/li>\n  <li>ta<span class='match'>x<\/span><\/li>\n<\/ul>"},"evals":[],"jsHooks":[]}</script>
<!--/html_preserve-->
``` r
str_subset(stringr::words, "x$") #something funky is happening in my viewer and I can't scroll so this is a check to see if the code actually work and it looks like it does!
```

    ## [1] "box" "sex" "six" "tax"

1.  Are exactly three letters long. (Don’t cheat by using str\_length()!) str\_view(stringr::words, "^...") \#gives you the first 3 letters of each word

``` r
str_view(stringr::words, "\\b[a-zA-Z0-9]{3,3}\\b", match = TRUE)
```

<!--html_preserve-->

<script type="application/json" data-for="htmlwidget-118450df7ea843db81df">{"x":{"html":"<ul>\n  <li><span class='match'>act<\/span><\/li>\n  <li><span class='match'>add<\/span><\/li>\n  <li><span class='match'>age<\/span><\/li>\n  <li><span class='match'>ago<\/span><\/li>\n  <li><span class='match'>air<\/span><\/li>\n  <li><span class='match'>all<\/span><\/li>\n  <li><span class='match'>and<\/span><\/li>\n  <li><span class='match'>any<\/span><\/li>\n  <li><span class='match'>arm<\/span><\/li>\n  <li><span class='match'>art<\/span><\/li>\n  <li><span class='match'>ask<\/span><\/li>\n  <li><span class='match'>bad<\/span><\/li>\n  <li><span class='match'>bag<\/span><\/li>\n  <li><span class='match'>bar<\/span><\/li>\n  <li><span class='match'>bed<\/span><\/li>\n  <li><span class='match'>bet<\/span><\/li>\n  <li><span class='match'>big<\/span><\/li>\n  <li><span class='match'>bit<\/span><\/li>\n  <li><span class='match'>box<\/span><\/li>\n  <li><span class='match'>boy<\/span><\/li>\n  <li><span class='match'>bus<\/span><\/li>\n  <li><span class='match'>but<\/span><\/li>\n  <li><span class='match'>buy<\/span><\/li>\n  <li><span class='match'>can<\/span><\/li>\n  <li><span class='match'>car<\/span><\/li>\n  <li><span class='match'>cat<\/span><\/li>\n  <li><span class='match'>cup<\/span><\/li>\n  <li><span class='match'>cut<\/span><\/li>\n  <li><span class='match'>dad<\/span><\/li>\n  <li><span class='match'>day<\/span><\/li>\n  <li><span class='match'>die<\/span><\/li>\n  <li><span class='match'>dog<\/span><\/li>\n  <li><span class='match'>dry<\/span><\/li>\n  <li><span class='match'>due<\/span><\/li>\n  <li><span class='match'>eat<\/span><\/li>\n  <li><span class='match'>egg<\/span><\/li>\n  <li><span class='match'>end<\/span><\/li>\n  <li><span class='match'>eye<\/span><\/li>\n  <li><span class='match'>far<\/span><\/li>\n  <li><span class='match'>few<\/span><\/li>\n  <li><span class='match'>fit<\/span><\/li>\n  <li><span class='match'>fly<\/span><\/li>\n  <li><span class='match'>for<\/span><\/li>\n  <li><span class='match'>fun<\/span><\/li>\n  <li><span class='match'>gas<\/span><\/li>\n  <li><span class='match'>get<\/span><\/li>\n  <li><span class='match'>god<\/span><\/li>\n  <li><span class='match'>guy<\/span><\/li>\n  <li><span class='match'>hit<\/span><\/li>\n  <li><span class='match'>hot<\/span><\/li>\n  <li><span class='match'>how<\/span><\/li>\n  <li><span class='match'>job<\/span><\/li>\n  <li><span class='match'>key<\/span><\/li>\n  <li><span class='match'>kid<\/span><\/li>\n  <li><span class='match'>lad<\/span><\/li>\n  <li><span class='match'>law<\/span><\/li>\n  <li><span class='match'>lay<\/span><\/li>\n  <li><span class='match'>leg<\/span><\/li>\n  <li><span class='match'>let<\/span><\/li>\n  <li><span class='match'>lie<\/span><\/li>\n  <li><span class='match'>lot<\/span><\/li>\n  <li><span class='match'>low<\/span><\/li>\n  <li><span class='match'>man<\/span><\/li>\n  <li><span class='match'>may<\/span><\/li>\n  <li><span class='match'>mrs<\/span><\/li>\n  <li><span class='match'>new<\/span><\/li>\n  <li><span class='match'>non<\/span><\/li>\n  <li><span class='match'>not<\/span><\/li>\n  <li><span class='match'>now<\/span><\/li>\n  <li><span class='match'>odd<\/span><\/li>\n  <li><span class='match'>off<\/span><\/li>\n  <li><span class='match'>old<\/span><\/li>\n  <li><span class='match'>one<\/span><\/li>\n  <li><span class='match'>out<\/span><\/li>\n  <li><span class='match'>own<\/span><\/li>\n  <li><span class='match'>pay<\/span><\/li>\n  <li><span class='match'>per<\/span><\/li>\n  <li><span class='match'>put<\/span><\/li>\n  <li><span class='match'>red<\/span><\/li>\n  <li><span class='match'>rid<\/span><\/li>\n  <li><span class='match'>run<\/span><\/li>\n  <li><span class='match'>say<\/span><\/li>\n  <li><span class='match'>see<\/span><\/li>\n  <li><span class='match'>set<\/span><\/li>\n  <li><span class='match'>sex<\/span><\/li>\n  <li><span class='match'>she<\/span><\/li>\n  <li><span class='match'>sir<\/span><\/li>\n  <li><span class='match'>sit<\/span><\/li>\n  <li><span class='match'>six<\/span><\/li>\n  <li><span class='match'>son<\/span><\/li>\n  <li><span class='match'>sun<\/span><\/li>\n  <li><span class='match'>tax<\/span><\/li>\n  <li><span class='match'>tea<\/span><\/li>\n  <li><span class='match'>ten<\/span><\/li>\n  <li><span class='match'>the<\/span><\/li>\n  <li><span class='match'>tie<\/span><\/li>\n  <li><span class='match'>too<\/span><\/li>\n  <li><span class='match'>top<\/span><\/li>\n  <li><span class='match'>try<\/span><\/li>\n  <li><span class='match'>two<\/span><\/li>\n  <li><span class='match'>use<\/span><\/li>\n  <li><span class='match'>war<\/span><\/li>\n  <li><span class='match'>way<\/span><\/li>\n  <li><span class='match'>wee<\/span><\/li>\n  <li><span class='match'>who<\/span><\/li>\n  <li><span class='match'>why<\/span><\/li>\n  <li><span class='match'>win<\/span><\/li>\n  <li><span class='match'>yes<\/span><\/li>\n  <li><span class='match'>yet<\/span><\/li>\n  <li><span class='match'>you<\/span><\/li>\n<\/ul>"},"evals":[],"jsHooks":[]}</script>
<!--/html_preserve-->
``` r
# SWEET, using the boundary "\b" expression you designate what you want selected, here it is alpha numeric, then {min,max} length of words
```

1.  Have seven letters or more

``` r
str_view(stringr::words, ".......", match = TRUE) 
```

<!--html_preserve-->

<script type="application/json" data-for="htmlwidget-56dcd2f1692bd29c8f48">{"x":{"html":"<ul>\n  <li><span class='match'>absolut<\/span>e<\/li>\n  <li><span class='match'>account<\/span><\/li>\n  <li><span class='match'>achieve<\/span><\/li>\n  <li><span class='match'>address<\/span><\/li>\n  <li><span class='match'>adverti<\/span>se<\/li>\n  <li><span class='match'>afterno<\/span>on<\/li>\n  <li><span class='match'>against<\/span><\/li>\n  <li><span class='match'>already<\/span><\/li>\n  <li><span class='match'>alright<\/span><\/li>\n  <li><span class='match'>althoug<\/span>h<\/li>\n  <li><span class='match'>america<\/span><\/li>\n  <li><span class='match'>another<\/span><\/li>\n  <li><span class='match'>apparen<\/span>t<\/li>\n  <li><span class='match'>appoint<\/span><\/li>\n  <li><span class='match'>approac<\/span>h<\/li>\n  <li><span class='match'>appropr<\/span>iate<\/li>\n  <li><span class='match'>arrange<\/span><\/li>\n  <li><span class='match'>associa<\/span>te<\/li>\n  <li><span class='match'>authori<\/span>ty<\/li>\n  <li><span class='match'>availab<\/span>le<\/li>\n  <li><span class='match'>balance<\/span><\/li>\n  <li><span class='match'>because<\/span><\/li>\n  <li><span class='match'>believe<\/span><\/li>\n  <li><span class='match'>benefit<\/span><\/li>\n  <li><span class='match'>between<\/span><\/li>\n  <li><span class='match'>brillia<\/span>nt<\/li>\n  <li><span class='match'>britain<\/span><\/li>\n  <li><span class='match'>brother<\/span><\/li>\n  <li><span class='match'>busines<\/span>s<\/li>\n  <li><span class='match'>certain<\/span><\/li>\n  <li><span class='match'>chairma<\/span>n<\/li>\n  <li><span class='match'>charact<\/span>er<\/li>\n  <li><span class='match'>Christm<\/span>as<\/li>\n  <li><span class='match'>colleag<\/span>ue<\/li>\n  <li><span class='match'>collect<\/span><\/li>\n  <li><span class='match'>college<\/span><\/li>\n  <li><span class='match'>comment<\/span><\/li>\n  <li><span class='match'>committ<\/span>ee<\/li>\n  <li><span class='match'>communi<\/span>ty<\/li>\n  <li><span class='match'>company<\/span><\/li>\n  <li><span class='match'>compare<\/span><\/li>\n  <li><span class='match'>complet<\/span>e<\/li>\n  <li><span class='match'>compute<\/span><\/li>\n  <li><span class='match'>concern<\/span><\/li>\n  <li><span class='match'>conditi<\/span>on<\/li>\n  <li><span class='match'>conside<\/span>r<\/li>\n  <li><span class='match'>consult<\/span><\/li>\n  <li><span class='match'>contact<\/span><\/li>\n  <li><span class='match'>continu<\/span>e<\/li>\n  <li><span class='match'>contrac<\/span>t<\/li>\n  <li><span class='match'>control<\/span><\/li>\n  <li><span class='match'>convers<\/span>e<\/li>\n  <li><span class='match'>correct<\/span><\/li>\n  <li><span class='match'>council<\/span><\/li>\n  <li><span class='match'>country<\/span><\/li>\n  <li><span class='match'>current<\/span><\/li>\n  <li><span class='match'>decisio<\/span>n<\/li>\n  <li><span class='match'>definit<\/span>e<\/li>\n  <li><span class='match'>departm<\/span>ent<\/li>\n  <li><span class='match'>describ<\/span>e<\/li>\n  <li><span class='match'>develop<\/span><\/li>\n  <li><span class='match'>differe<\/span>nce<\/li>\n  <li><span class='match'>difficu<\/span>lt<\/li>\n  <li><span class='match'>discuss<\/span><\/li>\n  <li><span class='match'>distric<\/span>t<\/li>\n  <li><span class='match'>documen<\/span>t<\/li>\n  <li><span class='match'>economy<\/span><\/li>\n  <li><span class='match'>educate<\/span><\/li>\n  <li><span class='match'>electri<\/span>c<\/li>\n  <li><span class='match'>encoura<\/span>ge<\/li>\n  <li><span class='match'>english<\/span><\/li>\n  <li><span class='match'>environ<\/span>ment<\/li>\n  <li><span class='match'>especia<\/span>l<\/li>\n  <li><span class='match'>evening<\/span><\/li>\n  <li><span class='match'>evidenc<\/span>e<\/li>\n  <li><span class='match'>example<\/span><\/li>\n  <li><span class='match'>exercis<\/span>e<\/li>\n  <li><span class='match'>expense<\/span><\/li>\n  <li><span class='match'>experie<\/span>nce<\/li>\n  <li><span class='match'>explain<\/span><\/li>\n  <li><span class='match'>express<\/span><\/li>\n  <li><span class='match'>finance<\/span><\/li>\n  <li><span class='match'>fortune<\/span><\/li>\n  <li><span class='match'>forward<\/span><\/li>\n  <li><span class='match'>functio<\/span>n<\/li>\n  <li><span class='match'>further<\/span><\/li>\n  <li><span class='match'>general<\/span><\/li>\n  <li><span class='match'>germany<\/span><\/li>\n  <li><span class='match'>goodbye<\/span><\/li>\n  <li><span class='match'>history<\/span><\/li>\n  <li><span class='match'>holiday<\/span><\/li>\n  <li><span class='match'>hospita<\/span>l<\/li>\n  <li><span class='match'>however<\/span><\/li>\n  <li><span class='match'>hundred<\/span><\/li>\n  <li><span class='match'>husband<\/span><\/li>\n  <li><span class='match'>identif<\/span>y<\/li>\n  <li><span class='match'>imagine<\/span><\/li>\n  <li><span class='match'>importa<\/span>nt<\/li>\n  <li><span class='match'>improve<\/span><\/li>\n  <li><span class='match'>include<\/span><\/li>\n  <li><span class='match'>increas<\/span>e<\/li>\n  <li><span class='match'>individ<\/span>ual<\/li>\n  <li><span class='match'>industr<\/span>y<\/li>\n  <li><span class='match'>instead<\/span><\/li>\n  <li><span class='match'>interes<\/span>t<\/li>\n  <li><span class='match'>introdu<\/span>ce<\/li>\n  <li><span class='match'>involve<\/span><\/li>\n  <li><span class='match'>kitchen<\/span><\/li>\n  <li><span class='match'>languag<\/span>e<\/li>\n  <li><span class='match'>machine<\/span><\/li>\n  <li><span class='match'>meaning<\/span><\/li>\n  <li><span class='match'>measure<\/span><\/li>\n  <li><span class='match'>mention<\/span><\/li>\n  <li><span class='match'>million<\/span><\/li>\n  <li><span class='match'>ministe<\/span>r<\/li>\n  <li><span class='match'>morning<\/span><\/li>\n  <li><span class='match'>necessa<\/span>ry<\/li>\n  <li><span class='match'>obvious<\/span><\/li>\n  <li><span class='match'>occasio<\/span>n<\/li>\n  <li><span class='match'>operate<\/span><\/li>\n  <li><span class='match'>opportu<\/span>nity<\/li>\n  <li><span class='match'>organiz<\/span>e<\/li>\n  <li><span class='match'>origina<\/span>l<\/li>\n  <li><span class='match'>otherwi<\/span>se<\/li>\n  <li><span class='match'>paragra<\/span>ph<\/li>\n  <li><span class='match'>particu<\/span>lar<\/li>\n  <li><span class='match'>pension<\/span><\/li>\n  <li><span class='match'>percent<\/span><\/li>\n  <li><span class='match'>perfect<\/span><\/li>\n  <li><span class='match'>perhaps<\/span><\/li>\n  <li><span class='match'>photogr<\/span>aph<\/li>\n  <li><span class='match'>picture<\/span><\/li>\n  <li><span class='match'>politic<\/span><\/li>\n  <li><span class='match'>positio<\/span>n<\/li>\n  <li><span class='match'>positiv<\/span>e<\/li>\n  <li><span class='match'>possibl<\/span>e<\/li>\n  <li><span class='match'>practis<\/span>e<\/li>\n  <li><span class='match'>prepare<\/span><\/li>\n  <li><span class='match'>present<\/span><\/li>\n  <li><span class='match'>pressur<\/span>e<\/li>\n  <li><span class='match'>presume<\/span><\/li>\n  <li><span class='match'>previou<\/span>s<\/li>\n  <li><span class='match'>private<\/span><\/li>\n  <li><span class='match'>probabl<\/span>e<\/li>\n  <li><span class='match'>problem<\/span><\/li>\n  <li><span class='match'>proceed<\/span><\/li>\n  <li><span class='match'>process<\/span><\/li>\n  <li><span class='match'>produce<\/span><\/li>\n  <li><span class='match'>product<\/span><\/li>\n  <li><span class='match'>program<\/span>me<\/li>\n  <li><span class='match'>project<\/span><\/li>\n  <li><span class='match'>propose<\/span><\/li>\n  <li><span class='match'>protect<\/span><\/li>\n  <li><span class='match'>provide<\/span><\/li>\n  <li><span class='match'>purpose<\/span><\/li>\n  <li><span class='match'>quality<\/span><\/li>\n  <li><span class='match'>quarter<\/span><\/li>\n  <li><span class='match'>questio<\/span>n<\/li>\n  <li><span class='match'>realise<\/span><\/li>\n  <li><span class='match'>receive<\/span><\/li>\n  <li><span class='match'>recogni<\/span>ze<\/li>\n  <li><span class='match'>recomme<\/span>nd<\/li>\n  <li><span class='match'>relatio<\/span>n<\/li>\n  <li><span class='match'>remembe<\/span>r<\/li>\n  <li><span class='match'>represe<\/span>nt<\/li>\n  <li><span class='match'>require<\/span><\/li>\n  <li><span class='match'>researc<\/span>h<\/li>\n  <li><span class='match'>resourc<\/span>e<\/li>\n  <li><span class='match'>respect<\/span><\/li>\n  <li><span class='match'>respons<\/span>ible<\/li>\n  <li><span class='match'>saturda<\/span>y<\/li>\n  <li><span class='match'>science<\/span><\/li>\n  <li><span class='match'>scotlan<\/span>d<\/li>\n  <li><span class='match'>secreta<\/span>ry<\/li>\n  <li><span class='match'>section<\/span><\/li>\n  <li><span class='match'>separat<\/span>e<\/li>\n  <li><span class='match'>serious<\/span><\/li>\n  <li><span class='match'>service<\/span><\/li>\n  <li><span class='match'>similar<\/span><\/li>\n  <li><span class='match'>situate<\/span><\/li>\n  <li><span class='match'>society<\/span><\/li>\n  <li><span class='match'>special<\/span><\/li>\n  <li><span class='match'>specifi<\/span>c<\/li>\n  <li><span class='match'>standar<\/span>d<\/li>\n  <li><span class='match'>station<\/span><\/li>\n  <li><span class='match'>straigh<\/span>t<\/li>\n  <li><span class='match'>strateg<\/span>y<\/li>\n  <li><span class='match'>structu<\/span>re<\/li>\n  <li><span class='match'>student<\/span><\/li>\n  <li><span class='match'>subject<\/span><\/li>\n  <li><span class='match'>succeed<\/span><\/li>\n  <li><span class='match'>suggest<\/span><\/li>\n  <li><span class='match'>support<\/span><\/li>\n  <li><span class='match'>suppose<\/span><\/li>\n  <li><span class='match'>surpris<\/span>e<\/li>\n  <li><span class='match'>telepho<\/span>ne<\/li>\n  <li><span class='match'>televis<\/span>ion<\/li>\n  <li><span class='match'>terribl<\/span>e<\/li>\n  <li><span class='match'>therefo<\/span>re<\/li>\n  <li><span class='match'>thirtee<\/span>n<\/li>\n  <li><span class='match'>thousan<\/span>d<\/li>\n  <li><span class='match'>through<\/span><\/li>\n  <li><span class='match'>thursda<\/span>y<\/li>\n  <li><span class='match'>togethe<\/span>r<\/li>\n  <li><span class='match'>tomorro<\/span>w<\/li>\n  <li><span class='match'>tonight<\/span><\/li>\n  <li><span class='match'>traffic<\/span><\/li>\n  <li><span class='match'>transpo<\/span>rt<\/li>\n  <li><span class='match'>trouble<\/span><\/li>\n  <li><span class='match'>tuesday<\/span><\/li>\n  <li><span class='match'>underst<\/span>and<\/li>\n  <li><span class='match'>univers<\/span>ity<\/li>\n  <li><span class='match'>various<\/span><\/li>\n  <li><span class='match'>village<\/span><\/li>\n  <li><span class='match'>wednesd<\/span>ay<\/li>\n  <li><span class='match'>welcome<\/span><\/li>\n  <li><span class='match'>whether<\/span><\/li>\n  <li><span class='match'>without<\/span><\/li>\n  <li><span class='match'>yesterd<\/span>ay<\/li>\n<\/ul>"},"evals":[],"jsHooks":[]}</script>
<!--/html_preserve-->
``` r
#Match = true resolves earlier issue, it highlights in the viewer only the matches
```

############ 14.3.3

1.  Create regular expressions to find all words that

``` r
 #a. starts with a vowel:
str_view(stringr::words, "^a|^e|^i|^o|^u", match = TRUE) 
```

<!--html_preserve-->

<script type="application/json" data-for="htmlwidget-bff50ec022bb3d33b8c6">{"x":{"html":"<ul>\n  <li><span class='match'>a<\/span><\/li>\n  <li><span class='match'>a<\/span>ble<\/li>\n  <li><span class='match'>a<\/span>bout<\/li>\n  <li><span class='match'>a<\/span>bsolute<\/li>\n  <li><span class='match'>a<\/span>ccept<\/li>\n  <li><span class='match'>a<\/span>ccount<\/li>\n  <li><span class='match'>a<\/span>chieve<\/li>\n  <li><span class='match'>a<\/span>cross<\/li>\n  <li><span class='match'>a<\/span>ct<\/li>\n  <li><span class='match'>a<\/span>ctive<\/li>\n  <li><span class='match'>a<\/span>ctual<\/li>\n  <li><span class='match'>a<\/span>dd<\/li>\n  <li><span class='match'>a<\/span>ddress<\/li>\n  <li><span class='match'>a<\/span>dmit<\/li>\n  <li><span class='match'>a<\/span>dvertise<\/li>\n  <li><span class='match'>a<\/span>ffect<\/li>\n  <li><span class='match'>a<\/span>fford<\/li>\n  <li><span class='match'>a<\/span>fter<\/li>\n  <li><span class='match'>a<\/span>fternoon<\/li>\n  <li><span class='match'>a<\/span>gain<\/li>\n  <li><span class='match'>a<\/span>gainst<\/li>\n  <li><span class='match'>a<\/span>ge<\/li>\n  <li><span class='match'>a<\/span>gent<\/li>\n  <li><span class='match'>a<\/span>go<\/li>\n  <li><span class='match'>a<\/span>gree<\/li>\n  <li><span class='match'>a<\/span>ir<\/li>\n  <li><span class='match'>a<\/span>ll<\/li>\n  <li><span class='match'>a<\/span>llow<\/li>\n  <li><span class='match'>a<\/span>lmost<\/li>\n  <li><span class='match'>a<\/span>long<\/li>\n  <li><span class='match'>a<\/span>lready<\/li>\n  <li><span class='match'>a<\/span>lright<\/li>\n  <li><span class='match'>a<\/span>lso<\/li>\n  <li><span class='match'>a<\/span>lthough<\/li>\n  <li><span class='match'>a<\/span>lways<\/li>\n  <li><span class='match'>a<\/span>merica<\/li>\n  <li><span class='match'>a<\/span>mount<\/li>\n  <li><span class='match'>a<\/span>nd<\/li>\n  <li><span class='match'>a<\/span>nother<\/li>\n  <li><span class='match'>a<\/span>nswer<\/li>\n  <li><span class='match'>a<\/span>ny<\/li>\n  <li><span class='match'>a<\/span>part<\/li>\n  <li><span class='match'>a<\/span>pparent<\/li>\n  <li><span class='match'>a<\/span>ppear<\/li>\n  <li><span class='match'>a<\/span>pply<\/li>\n  <li><span class='match'>a<\/span>ppoint<\/li>\n  <li><span class='match'>a<\/span>pproach<\/li>\n  <li><span class='match'>a<\/span>ppropriate<\/li>\n  <li><span class='match'>a<\/span>rea<\/li>\n  <li><span class='match'>a<\/span>rgue<\/li>\n  <li><span class='match'>a<\/span>rm<\/li>\n  <li><span class='match'>a<\/span>round<\/li>\n  <li><span class='match'>a<\/span>rrange<\/li>\n  <li><span class='match'>a<\/span>rt<\/li>\n  <li><span class='match'>a<\/span>s<\/li>\n  <li><span class='match'>a<\/span>sk<\/li>\n  <li><span class='match'>a<\/span>ssociate<\/li>\n  <li><span class='match'>a<\/span>ssume<\/li>\n  <li><span class='match'>a<\/span>t<\/li>\n  <li><span class='match'>a<\/span>ttend<\/li>\n  <li><span class='match'>a<\/span>uthority<\/li>\n  <li><span class='match'>a<\/span>vailable<\/li>\n  <li><span class='match'>a<\/span>ware<\/li>\n  <li><span class='match'>a<\/span>way<\/li>\n  <li><span class='match'>a<\/span>wful<\/li>\n  <li><span class='match'>e<\/span>ach<\/li>\n  <li><span class='match'>e<\/span>arly<\/li>\n  <li><span class='match'>e<\/span>ast<\/li>\n  <li><span class='match'>e<\/span>asy<\/li>\n  <li><span class='match'>e<\/span>at<\/li>\n  <li><span class='match'>e<\/span>conomy<\/li>\n  <li><span class='match'>e<\/span>ducate<\/li>\n  <li><span class='match'>e<\/span>ffect<\/li>\n  <li><span class='match'>e<\/span>gg<\/li>\n  <li><span class='match'>e<\/span>ight<\/li>\n  <li><span class='match'>e<\/span>ither<\/li>\n  <li><span class='match'>e<\/span>lect<\/li>\n  <li><span class='match'>e<\/span>lectric<\/li>\n  <li><span class='match'>e<\/span>leven<\/li>\n  <li><span class='match'>e<\/span>lse<\/li>\n  <li><span class='match'>e<\/span>mploy<\/li>\n  <li><span class='match'>e<\/span>ncourage<\/li>\n  <li><span class='match'>e<\/span>nd<\/li>\n  <li><span class='match'>e<\/span>ngine<\/li>\n  <li><span class='match'>e<\/span>nglish<\/li>\n  <li><span class='match'>e<\/span>njoy<\/li>\n  <li><span class='match'>e<\/span>nough<\/li>\n  <li><span class='match'>e<\/span>nter<\/li>\n  <li><span class='match'>e<\/span>nvironment<\/li>\n  <li><span class='match'>e<\/span>qual<\/li>\n  <li><span class='match'>e<\/span>special<\/li>\n  <li><span class='match'>e<\/span>urope<\/li>\n  <li><span class='match'>e<\/span>ven<\/li>\n  <li><span class='match'>e<\/span>vening<\/li>\n  <li><span class='match'>e<\/span>ver<\/li>\n  <li><span class='match'>e<\/span>very<\/li>\n  <li><span class='match'>e<\/span>vidence<\/li>\n  <li><span class='match'>e<\/span>xact<\/li>\n  <li><span class='match'>e<\/span>xample<\/li>\n  <li><span class='match'>e<\/span>xcept<\/li>\n  <li><span class='match'>e<\/span>xcuse<\/li>\n  <li><span class='match'>e<\/span>xercise<\/li>\n  <li><span class='match'>e<\/span>xist<\/li>\n  <li><span class='match'>e<\/span>xpect<\/li>\n  <li><span class='match'>e<\/span>xpense<\/li>\n  <li><span class='match'>e<\/span>xperience<\/li>\n  <li><span class='match'>e<\/span>xplain<\/li>\n  <li><span class='match'>e<\/span>xpress<\/li>\n  <li><span class='match'>e<\/span>xtra<\/li>\n  <li><span class='match'>e<\/span>ye<\/li>\n  <li><span class='match'>i<\/span>dea<\/li>\n  <li><span class='match'>i<\/span>dentify<\/li>\n  <li><span class='match'>i<\/span>f<\/li>\n  <li><span class='match'>i<\/span>magine<\/li>\n  <li><span class='match'>i<\/span>mportant<\/li>\n  <li><span class='match'>i<\/span>mprove<\/li>\n  <li><span class='match'>i<\/span>n<\/li>\n  <li><span class='match'>i<\/span>nclude<\/li>\n  <li><span class='match'>i<\/span>ncome<\/li>\n  <li><span class='match'>i<\/span>ncrease<\/li>\n  <li><span class='match'>i<\/span>ndeed<\/li>\n  <li><span class='match'>i<\/span>ndividual<\/li>\n  <li><span class='match'>i<\/span>ndustry<\/li>\n  <li><span class='match'>i<\/span>nform<\/li>\n  <li><span class='match'>i<\/span>nside<\/li>\n  <li><span class='match'>i<\/span>nstead<\/li>\n  <li><span class='match'>i<\/span>nsure<\/li>\n  <li><span class='match'>i<\/span>nterest<\/li>\n  <li><span class='match'>i<\/span>nto<\/li>\n  <li><span class='match'>i<\/span>ntroduce<\/li>\n  <li><span class='match'>i<\/span>nvest<\/li>\n  <li><span class='match'>i<\/span>nvolve<\/li>\n  <li><span class='match'>i<\/span>ssue<\/li>\n  <li><span class='match'>i<\/span>t<\/li>\n  <li><span class='match'>i<\/span>tem<\/li>\n  <li><span class='match'>o<\/span>bvious<\/li>\n  <li><span class='match'>o<\/span>ccasion<\/li>\n  <li><span class='match'>o<\/span>dd<\/li>\n  <li><span class='match'>o<\/span>f<\/li>\n  <li><span class='match'>o<\/span>ff<\/li>\n  <li><span class='match'>o<\/span>ffer<\/li>\n  <li><span class='match'>o<\/span>ffice<\/li>\n  <li><span class='match'>o<\/span>ften<\/li>\n  <li><span class='match'>o<\/span>kay<\/li>\n  <li><span class='match'>o<\/span>ld<\/li>\n  <li><span class='match'>o<\/span>n<\/li>\n  <li><span class='match'>o<\/span>nce<\/li>\n  <li><span class='match'>o<\/span>ne<\/li>\n  <li><span class='match'>o<\/span>nly<\/li>\n  <li><span class='match'>o<\/span>pen<\/li>\n  <li><span class='match'>o<\/span>perate<\/li>\n  <li><span class='match'>o<\/span>pportunity<\/li>\n  <li><span class='match'>o<\/span>ppose<\/li>\n  <li><span class='match'>o<\/span>r<\/li>\n  <li><span class='match'>o<\/span>rder<\/li>\n  <li><span class='match'>o<\/span>rganize<\/li>\n  <li><span class='match'>o<\/span>riginal<\/li>\n  <li><span class='match'>o<\/span>ther<\/li>\n  <li><span class='match'>o<\/span>therwise<\/li>\n  <li><span class='match'>o<\/span>ught<\/li>\n  <li><span class='match'>o<\/span>ut<\/li>\n  <li><span class='match'>o<\/span>ver<\/li>\n  <li><span class='match'>o<\/span>wn<\/li>\n  <li><span class='match'>u<\/span>nder<\/li>\n  <li><span class='match'>u<\/span>nderstand<\/li>\n  <li><span class='match'>u<\/span>nion<\/li>\n  <li><span class='match'>u<\/span>nit<\/li>\n  <li><span class='match'>u<\/span>nite<\/li>\n  <li><span class='match'>u<\/span>niversity<\/li>\n  <li><span class='match'>u<\/span>nless<\/li>\n  <li><span class='match'>u<\/span>ntil<\/li>\n  <li><span class='match'>u<\/span>p<\/li>\n  <li><span class='match'>u<\/span>pon<\/li>\n  <li><span class='match'>u<\/span>se<\/li>\n  <li><span class='match'>u<\/span>sual<\/li>\n<\/ul>"},"evals":[],"jsHooks":[]}</script>
<!--/html_preserve-->
``` r
#the | indicates "or" between each matching option, early attemps show 
#that you must have ^ for each vowel, that is you must designate position after 
#every or otherwise it will pick any ol' word with an e,i,o,u
 #b. only contain consonants
str_view(stringr::words, "!a|!e|!i|!o|!u", match = TRUE) 
```

<!--html_preserve-->

<script type="application/json" data-for="htmlwidget-8601def1f2b946ee60cc">{"x":{"html":"<ul>\n  <li><\/li>\n<\/ul>"},"evals":[],"jsHooks":[]}</script>
<!--/html_preserve-->
``` r
#it does not appear there are any all consonant words
 #c. end with ed, but not eed
str_view(stringr::words, "ed$", match = TRUE) 
```

<!--html_preserve-->

<script type="application/json" data-for="htmlwidget-49f0501da87d2e120500">{"x":{"html":"<ul>\n  <li>b<span class='match'>ed<\/span><\/li>\n  <li>fe<span class='match'>ed<\/span><\/li>\n  <li>hundr<span class='match'>ed<\/span><\/li>\n  <li>inde<span class='match'>ed<\/span><\/li>\n  <li>ne<span class='match'>ed<\/span><\/li>\n  <li>proce<span class='match'>ed<\/span><\/li>\n  <li>r<span class='match'>ed<\/span><\/li>\n  <li>spe<span class='match'>ed<\/span><\/li>\n  <li>succe<span class='match'>ed<\/span><\/li>\n<\/ul>"},"evals":[],"jsHooks":[]}</script>
<!--/html_preserve-->
``` r
#grabs all that end in -ed AND eed, but how to get rid of those eed?
```

``` r
########str_view(stringr::words, "\\b[a-zA-Z0-9]{3,3}\\bed$", match = TRUE)
#str_view(stringr::words, "["ed$"]", match = TRUE) #I have struggled through several iterations of modifying this approach :(
  #d. ending with -ing or -ise
str_view(stringr::words, "ing$|ise", match = TRUE)
```

<!--html_preserve-->

<script type="application/json" data-for="htmlwidget-d5c1db80d5f649aae72b">{"x":{"html":"<ul>\n  <li>advert<span class='match'>ise<\/span><\/li>\n  <li>br<span class='match'>ing<\/span><\/li>\n  <li>dur<span class='match'>ing<\/span><\/li>\n  <li>even<span class='match'>ing<\/span><\/li>\n  <li>exerc<span class='match'>ise<\/span><\/li>\n  <li>k<span class='match'>ing<\/span><\/li>\n  <li>mean<span class='match'>ing<\/span><\/li>\n  <li>morn<span class='match'>ing<\/span><\/li>\n  <li>otherw<span class='match'>ise<\/span><\/li>\n  <li>pract<span class='match'>ise<\/span><\/li>\n  <li>ra<span class='match'>ise<\/span><\/li>\n  <li>real<span class='match'>ise<\/span><\/li>\n  <li>r<span class='match'>ing<\/span><\/li>\n  <li>r<span class='match'>ise<\/span><\/li>\n  <li>s<span class='match'>ing<\/span><\/li>\n  <li>surpr<span class='match'>ise<\/span><\/li>\n  <li>th<span class='match'>ing<\/span><\/li>\n<\/ul>"},"evals":[],"jsHooks":[]}</script>
<!--/html_preserve-->
``` r
#2. Empirically verify the rule "i before e except after c"
str_view(stringr::words, "cei", match = TRUE)
```

<!--html_preserve-->

<script type="application/json" data-for="htmlwidget-885d1fd8ee9738d3b01b">{"x":{"html":"<ul>\n  <li>re<span class='match'>cei<\/span>ve<\/li>\n<\/ul>"},"evals":[],"jsHooks":[]}</script>
<!--/html_preserve-->
``` r
#3. Is "q" always followed by "u"? 
  #Yes.
str_view(stringr::words, "qu", match = TRUE) # there are 10 occurences where q comes directly before u
```

<!--html_preserve-->

<script type="application/json" data-for="htmlwidget-90bf5f5c01f5d2c06838">{"x":{"html":"<ul>\n  <li>e<span class='match'>qu<\/span>al<\/li>\n  <li><span class='match'>qu<\/span>ality<\/li>\n  <li><span class='match'>qu<\/span>arter<\/li>\n  <li><span class='match'>qu<\/span>estion<\/li>\n  <li><span class='match'>qu<\/span>ick<\/li>\n  <li><span class='match'>qu<\/span>id<\/li>\n  <li><span class='match'>qu<\/span>iet<\/li>\n  <li><span class='match'>qu<\/span>ite<\/li>\n  <li>re<span class='match'>qu<\/span>ire<\/li>\n  <li>s<span class='match'>qu<\/span>are<\/li>\n<\/ul>"},"evals":[],"jsHooks":[]}</script>
<!--/html_preserve-->
``` r
str_view(stringr::words, "q.u", match = TRUE) # there are no occurence where q is seperated by some character then followed by u
```

<!--html_preserve-->

<script type="application/json" data-for="htmlwidget-67dffbe75fa1ef3282bc">{"x":{"html":"<ul>\n  <li><\/li>\n<\/ul>"},"evals":[],"jsHooks":[]}</script>
<!--/html_preserve-->
``` r
str_view(stringr::words, "uq", match = TRUE) #no occurences where u is directly before q
```

<!--html_preserve-->

<script type="application/json" data-for="htmlwidget-b2da2de7c1bfd3993248">{"x":{"html":"<ul>\n  <li><\/li>\n<\/ul>"},"evals":[],"jsHooks":[]}</script>
<!--/html_preserve-->
``` r
str_view(stringr::words, "u.q", match = TRUE) 
```

<!--html_preserve-->

<script type="application/json" data-for="htmlwidget-29438f888d14fc34c4be">{"x":{"html":"<ul>\n  <li><\/li>\n<\/ul>"},"evals":[],"jsHooks":[]}</script>
<!--/html_preserve-->
``` r
#4. Write a regular expression that matches a word if its probably written in British English, not American English:

str_view(stringr::words, "..our$", match = TRUE) #the ... gets rid of any 4 and 5 letter words that are ubiquitous to both American and British english like four and flour
```

<!--html_preserve-->

<script type="application/json" data-for="htmlwidget-bf5f1b4fb8e1a2abe22f">{"x":{"html":"<ul>\n  <li>c<span class='match'>olour<\/span><\/li>\n  <li>f<span class='match'>avour<\/span><\/li>\n  <li>l<span class='match'>abour<\/span><\/li>\n<\/ul>"},"evals":[],"jsHooks":[]}</script>
<!--/html_preserve-->
``` r
#5. Create a regular expression that will match telephone numbers as commonly written in your country
c<- c("555-555-5555", "home 555-555-5551", "mobile555-555-5552")

str_view(c, "...\\-...\\-....") 
```

<!--html_preserve-->

<script type="application/json" data-for="htmlwidget-c4f0917ffe134367c7cc">{"x":{"html":"<ul>\n  <li><span class='match'>555-555-5555<\/span><\/li>\n  <li>home <span class='match'>555-555-5551<\/span><\/li>\n  <li>mobile<span class='match'>555-555-5552<\/span><\/li>\n<\/ul>"},"evals":[],"jsHooks":[]}</script>
<!--/html_preserve-->
``` r
str_subset(c, "...\\-...\\-....") # we could subset all the strings with a phone number
```

    ## [1] "555-555-5555"       "home 555-555-5551"  "mobile555-555-5552"

############ 14.3.4

``` r
#1. Describe the equivalents of ?, +, *, in {m,n} form.
  #Take R for data science's example:
x <- "1888 is the longest year in Roman numerals: MDCCCLXXXVIII"
str_view(x, "CC?")
```

<!--html_preserve-->

<script type="application/json" data-for="htmlwidget-658cb2e633debffe5504">{"x":{"html":"<ul>\n  <li>1888 is the longest year in Roman numerals: MD<span class='match'>CC<\/span>CLXXXVIII<\/li>\n<\/ul>"},"evals":[],"jsHooks":[]}</script>
<!--/html_preserve-->
``` r
str_view(x, "C{1,2}")
```

<!--html_preserve-->

<script type="application/json" data-for="htmlwidget-6588e9174b22ed2ded9e">{"x":{"html":"<ul>\n  <li>1888 is the longest year in Roman numerals: MD<span class='match'>CC<\/span>CLXXXVIII<\/li>\n<\/ul>"},"evals":[],"jsHooks":[]}</script>
<!--/html_preserve-->
``` r
  #? picks up the repition at the minimum length, that is {1,2}
str_view(x, "CC+")
```

<!--html_preserve-->

<script type="application/json" data-for="htmlwidget-6d2a340014390402a36e">{"x":{"html":"<ul>\n  <li>1888 is the longest year in Roman numerals: MD<span class='match'>CCC<\/span>LXXXVIII<\/li>\n<\/ul>"},"evals":[],"jsHooks":[]}</script>
<!--/html_preserve-->
``` r
str_view(x, "CC{1,3}")
```

<!--html_preserve-->

<script type="application/json" data-for="htmlwidget-03c9834612fd8d0076b9">{"x":{"html":"<ul>\n  <li>1888 is the longest year in Roman numerals: MD<span class='match'>CCC<\/span>LXXXVIII<\/li>\n<\/ul>"},"evals":[],"jsHooks":[]}</script>
<!--/html_preserve-->
``` r
  # + picks up all repeated characters starting with a length of 1 and will match all repetitions to n equivalent to {1,n}
str_view(x, "MD*") # * will pick up character strings even if the repition is 0
```

<!--html_preserve-->

<script type="application/json" data-for="htmlwidget-79b949aeb889b21f94b9">{"x":{"html":"<ul>\n  <li>1888 is the longest year in Roman numerals: <span class='match'>MD<\/span>CCCLXXXVIII<\/li>\n<\/ul>"},"evals":[],"jsHooks":[]}</script>
<!--/html_preserve-->
``` r
str_view(x, "MD{0,1}")
```

<!--html_preserve-->

<script type="application/json" data-for="htmlwidget-8d412d2b3d6819bc7a6b">{"x":{"html":"<ul>\n  <li>1888 is the longest year in Roman numerals: <span class='match'>MD<\/span>CCCLXXXVIII<\/li>\n<\/ul>"},"evals":[],"jsHooks":[]}</script>
<!--/html_preserve-->
``` r
#2. a. ^.*$ - I'm totally baffled by this string...^indicates the beginning anchor, $ is the ending anchor, . expresses any character, and * highlights repetition of 0 or more times... none of the characters have been escaped


  #b. "\\{.+\\}" This is an equally confusing expression. match any character that repeats more than once?
str_view(x, "\\{.+\\}")
```

<!--html_preserve-->

<script type="application/json" data-for="htmlwidget-9d1fab631ede3d304c00">{"x":{"html":"<ul>\n  <li>1888 is the longest year in Roman numerals: MDCCCLXXXVIII<\/li>\n<\/ul>"},"evals":[],"jsHooks":[]}</script>
<!--/html_preserve-->
``` r
  #c. \d{4}-\d{2}-\d{2} This expression matches a string that starts with 4 digits, is seperated by - followed by two digits, another - and lastly 2 more digits
y<- c("home 1234-12-12")
str_view(y, "\\d{4}-\\d{2}-\\d{2}")
```

<!--html_preserve-->

<script type="application/json" data-for="htmlwidget-dbe36ea9ee74b8ea928b">{"x":{"html":"<ul>\n  <li>home <span class='match'>1234-12-12<\/span><\/li>\n<\/ul>"},"evals":[],"jsHooks":[]}</script>
<!--/html_preserve-->
``` r
#d. "\\\\{4}" This expression escapes the \ and give the proceeding characters, was there maybe a \d that was supposed to be in here?
z<- c("\\123456")
z<- c("\\ancsdfs")
str_view(z, "\\\\{4}")
```

<!--html_preserve-->

<script type="application/json" data-for="htmlwidget-53a6b4072da547846bdd">{"x":{"html":"<ul>\n  <li>\\ancsdfs<\/li>\n<\/ul>"},"evals":[],"jsHooks":[]}</script>
<!--/html_preserve-->
``` r
#3. Create regular expressions to find all words that:
  #a.start with three consonants 
str_view(words, "^[^aeiou]{3,3}", match = TRUE)
```

<!--html_preserve-->

<script type="application/json" data-for="htmlwidget-3d25bd2df30667edd332">{"x":{"html":"<ul>\n  <li><span class='match'>Chr<\/span>ist<\/li>\n  <li><span class='match'>Chr<\/span>istmas<\/li>\n  <li><span class='match'>dry<\/span><\/li>\n  <li><span class='match'>fly<\/span><\/li>\n  <li><span class='match'>mrs<\/span><\/li>\n  <li><span class='match'>sch<\/span>eme<\/li>\n  <li><span class='match'>sch<\/span>ool<\/li>\n  <li><span class='match'>str<\/span>aight<\/li>\n  <li><span class='match'>str<\/span>ategy<\/li>\n  <li><span class='match'>str<\/span>eet<\/li>\n  <li><span class='match'>str<\/span>ike<\/li>\n  <li><span class='match'>str<\/span>ong<\/li>\n  <li><span class='match'>str<\/span>ucture<\/li>\n  <li><span class='match'>sys<\/span>tem<\/li>\n  <li><span class='match'>thr<\/span>ee<\/li>\n  <li><span class='match'>thr<\/span>ough<\/li>\n  <li><span class='match'>thr<\/span>ow<\/li>\n  <li><span class='match'>try<\/span><\/li>\n  <li><span class='match'>typ<\/span>e<\/li>\n  <li><span class='match'>why<\/span><\/li>\n<\/ul>"},"evals":[],"jsHooks":[]}</script>
<!--/html_preserve-->
``` r
  #b. have three or more vowels in a row
     str_view(stringr::words, "[aeiou]{3,3}", match = TRUE) 
```

<!--html_preserve-->

<script type="application/json" data-for="htmlwidget-9c6c50e3fc4aeaaccbb1">{"x":{"html":"<ul>\n  <li>b<span class='match'>eau<\/span>ty<\/li>\n  <li>obv<span class='match'>iou<\/span>s<\/li>\n  <li>prev<span class='match'>iou<\/span>s<\/li>\n  <li>q<span class='match'>uie<\/span>t<\/li>\n  <li>ser<span class='match'>iou<\/span>s<\/li>\n  <li>var<span class='match'>iou<\/span>s<\/li>\n<\/ul>"},"evals":[],"jsHooks":[]}</script>
<!--/html_preserve-->
############# 14.3.5

``` r
#1. describe what the expression below will match:
     #a. (.)\1\1
     c<-c("aaaaabbbbcccbcbcbcb", "a", "b") 
str_view(c, "(.)\\1\\1") #it matches the first group "aaa"
```

<!--html_preserve-->

<script type="application/json" data-for="htmlwidget-3fb64239b2eef4b906ee">{"x":{"html":"<ul>\n  <li><span class='match'>aaa<\/span>aabbbbcccbcbcbcb<\/li>\n  <li>a<\/li>\n  <li>b<\/li>\n<\/ul>"},"evals":[],"jsHooks":[]}</script>
<!--/html_preserve-->
``` r
  #b. "(.)(.)\\2\\1"
str_view(c, "(.)(.)\\2\\1") #it matches the first group "aaaa"
```

<!--html_preserve-->

<script type="application/json" data-for="htmlwidget-f70bc4943220c81b94c4">{"x":{"html":"<ul>\n  <li><span class='match'>aaaa<\/span>abbbbcccbcbcbcb<\/li>\n  <li>a<\/li>\n  <li>b<\/li>\n<\/ul>"},"evals":[],"jsHooks":[]}</script>
<!--/html_preserve-->
``` r
  #c. (..)\1
str_view(c, "(..)\\1") #same result as "(.)(.)\\2\\1", 2 characters repeated once 
```

<!--html_preserve-->

<script type="application/json" data-for="htmlwidget-37180c526b78149d3129">{"x":{"html":"<ul>\n  <li><span class='match'>aaaa<\/span>abbbbcccbcbcbcb<\/li>\n  <li>a<\/li>\n  <li>b<\/li>\n<\/ul>"},"evals":[],"jsHooks":[]}</script>
<!--/html_preserve-->
``` r
  #d. "(.).\\1.\\1"
str_view(c, "(.).\\1.\\1") #same result as last 2 expressions
```

<!--html_preserve-->

<script type="application/json" data-for="htmlwidget-d07c6b7f6eff6fcaae5d">{"x":{"html":"<ul>\n  <li><span class='match'>aaaaa<\/span>bbbbcccbcbcbcb<\/li>\n  <li>a<\/li>\n  <li>b<\/li>\n<\/ul>"},"evals":[],"jsHooks":[]}</script>
<!--/html_preserve-->
``` r
  #e. "(.)(.)(.).*\\3\\2\\1"
str_view(c, "(.)(.)(.).*\\3\\2\\1") # I actually have no idea what this expression is saying, other than the fact it pulls out the repetition of "cbcbcbc", maybe (.)(.)(.) refers to the 3 characters, . refers to the middle character b and * wants the repetition of that sequence, however I am still unsure what the heck the \\3\\2\1 are referring to
```

<!--html_preserve-->

<script type="application/json" data-for="htmlwidget-fbba88dee9939585d6bd">{"x":{"html":"<ul>\n  <li>aaaaabbbbcc<span class='match'>cbcbcbc<\/span>b<\/li>\n  <li>a<\/li>\n  <li>b<\/li>\n<\/ul>"},"evals":[],"jsHooks":[]}</script>
<!--/html_preserve-->
``` r
#2. Construct regular expressions to match words that:
  #a. start and end with the same character
c<- c("bulb","toast", "noun")
str_view(c, "^(.)(.)$\\1") #well that doesn't work
```

<!--html_preserve-->

<script type="application/json" data-for="htmlwidget-abe785535772f5c5a316">{"x":{"html":"<ul>\n  <li>bulb<\/li>\n  <li>toast<\/li>\n  <li>noun<\/li>\n<\/ul>"},"evals":[],"jsHooks":[]}</script>
<!--/html_preserve-->
``` r
  #b. Contain a repeated pair of letters (e.g. “church” contains “ch” repeated twice.)
r<-c("church", "fright")
#str_view(r, "(..)\\2")
#str_view(r, "(..)\\1")
str_view(r, "(..)") #that just gets the first two letters...
```

<!--html_preserve-->

<script type="application/json" data-for="htmlwidget-1e7ca4505f09c8de10c1">{"x":{"html":"<ul>\n  <li><span class='match'>ch<\/span>urch<\/li>\n  <li><span class='match'>fr<\/span>ight<\/li>\n<\/ul>"},"evals":[],"jsHooks":[]}</script>
<!--/html_preserve-->
``` r
#but how do we move on to matching repitition
#str_view(r, "(..)\\1") #nope
#str_view(r, "(..)*\\6")
  #c. Contain one letter repeated in at least three places (e.g. “eleven” contains three “e”s.) 

x<- c("bananana", "cococonutcoco", "cucucumber")
#str_view(x, "(..)\\1")
```

############# 14.4.2

``` r
#Life is often easier if you build a series of simple regexps rather than one big monolith
#str_detect() #let's you suss out patterns and will return a logical vector of the same length as the input. by converting the output object to numeric the TRUEs and FALSEs become binary and you can use sum() and mean()
mean(str_detect(words, "[aeiou]$")) #words that end with a vowel
```

    ## [1] 0.2765306

``` r
no_vowels_1 <- !str_detect(words, "[aeiou]")# all the words that don't have at least 1 vowel

#1.For each of the following challenges, try solving it by using both a single regular expression, and a combination of multiple str_detect() calls
  #a. Find all words that start or end with x.
str_detect(words, "x$") #this gives you a logical output of TRUEs and FALSEs
```

    ##   [1] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ##  [12] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ##  [23] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ##  [34] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ##  [45] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ##  [56] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ##  [67] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ##  [78] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ##  [89] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [100] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE  TRUE FALSE FALSE
    ## [111] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [122] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [133] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [144] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [155] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [166] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [177] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [188] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [199] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [210] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [221] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [232] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [243] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [254] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [265] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [276] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [287] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [298] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [309] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [320] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [331] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [342] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [353] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [364] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [375] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [386] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [397] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [408] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [419] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [430] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [441] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [452] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [463] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [474] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [485] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [496] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [507] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [518] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [529] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [540] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [551] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [562] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [573] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [584] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [595] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [606] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [617] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [628] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [639] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [650] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [661] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [672] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [683] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [694] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [705] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [716] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [727] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [738] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE  TRUE FALSE
    ## [749] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [760] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [771] FALSE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [782] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [793] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [804] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [815] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [826] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [837] FALSE FALSE FALSE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [848] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [859] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [870] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [881] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [892] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [903] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [914] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [925] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [936] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [947] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [958] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [969] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [980] FALSE

``` r
str_view_all(words, "x$", match = TRUE) #this shows you the actual words that end with x
```

<!--html_preserve-->

<script type="application/json" data-for="htmlwidget-5e81920efeacf67b39ca">{"x":{"html":"<ul>\n  <li>bo<span class='match'>x<\/span><\/li>\n  <li>se<span class='match'>x<\/span><\/li>\n  <li>si<span class='match'>x<\/span><\/li>\n  <li>ta<span class='match'>x<\/span><\/li>\n<\/ul>"},"evals":[],"jsHooks":[]}</script>
<!--/html_preserve-->
``` r
str_view_all(words, "^x", match = TRUE) #no words begin with x
```

<!--html_preserve-->

<script type="application/json" data-for="htmlwidget-eecccd85ee7a065d3230">{"x":{"html":"<ul>\n  <li><\/li>\n<\/ul>"},"evals":[],"jsHooks":[]}</script>
<!--/html_preserve-->
``` r
#another way to write this:
  words[str_detect(words, "x$")]
```

    ## [1] "box" "sex" "six" "tax"

``` r
  str_subset(words, "x$")
```

    ## [1] "box" "sex" "six" "tax"

``` r
  #b. Find all words that start with a vowel and end with a consonant
str_detect(words, "^[aeiou][^aeiou]$")
```

    ##   [1] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ##  [12] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ##  [23] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ##  [34] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ##  [45] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE  TRUE
    ##  [56] FALSE FALSE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ##  [67] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ##  [78] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ##  [89] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [100] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [111] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [122] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [133] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [144] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [155] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [166] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [177] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [188] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [199] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [210] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [221] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [232] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [243] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [254] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [265] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [276] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [287] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [298] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [309] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [320] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [331] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [342] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [353] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [364] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [375] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [386] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [397] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [408] FALSE FALSE FALSE FALSE FALSE FALSE  TRUE FALSE FALSE FALSE  TRUE
    ## [419] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [430] FALSE FALSE FALSE FALSE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE
    ## [441] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [452] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [463] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [474] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [485] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [496] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [507] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [518] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [529] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [540] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [551] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [562] FALSE FALSE FALSE FALSE FALSE FALSE  TRUE FALSE FALSE FALSE FALSE
    ## [573] FALSE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE  TRUE
    ## [584] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [595] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [606] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [617] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [628] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [639] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [650] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [661] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [672] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [683] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [694] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [705] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [716] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [727] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [738] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [749] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [760] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [771] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [782] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [793] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [804] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [815] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [826] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [837] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [848] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [859] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [870] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [881] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [892] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [903] FALSE FALSE FALSE FALSE FALSE FALSE FALSE  TRUE FALSE FALSE FALSE
    ## [914] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [925] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [936] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [947] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [958] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [969] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
    ## [980] FALSE

``` r
  str_view_all(words, "^[aeiou][^aeiou]$", match = TRUE) #unfortunately this only gives youthe two letter words that start with a vowel and end with a consonant
```

<!--html_preserve-->

<script type="application/json" data-for="htmlwidget-cc43a507e1c6bfc281ca">{"x":{"html":"<ul>\n  <li><span class='match'>as<\/span><\/li>\n  <li><span class='match'>at<\/span><\/li>\n  <li><span class='match'>if<\/span><\/li>\n  <li><span class='match'>in<\/span><\/li>\n  <li><span class='match'>it<\/span><\/li>\n  <li><span class='match'>of<\/span><\/li>\n  <li><span class='match'>on<\/span><\/li>\n  <li><span class='match'>or<\/span><\/li>\n  <li><span class='match'>up<\/span><\/li>\n<\/ul>"},"evals":[],"jsHooks":[]}</script>
<!--/html_preserve-->
``` r
#2. What word has the highest number of vowels? What word has the highest proportion of vowels? (Hint: what is the denominator?)
  df<- tibble(word = words, i = seq_along(word))
#df %>% mutate(vowels = str_count(word, "[aeiou]"),consonants = str_count(word, "[^aeiou]"))
#df %>% select("word", "consonants") %>% summary(max) #this should work if it were being read as a dataframe with columns for vowels and consonants, however it is not so its not working...either.
```

############# 14.4.3

``` r
#1. In the previous example, you might have noticed that the regular expression matched “flickered”, fix the code:

colours <- c("red", "orange", "yellow", "green", "blue", "purple")
colour_match <- str_c(colours, collapse = "|")
colour_match
```

    ## [1] "red|orange|yellow|green|blue|purple"

``` r
more <- sentences[str_count(sentences, colour_match) > 1]
str_view_all(more, colour_match)
```

<!--html_preserve-->

<script type="application/json" data-for="htmlwidget-733cad76fe4eb54f7db8">{"x":{"html":"<ul>\n  <li>It is hard to erase <span class='match'>blue<\/span> or <span class='match'>red<\/span> ink.<\/li>\n  <li>The <span class='match'>green<\/span> light in the brown box flicke<span class='match'>red<\/span>.<\/li>\n  <li>The sky in the west is tinged with <span class='match'>orange<\/span> <span class='match'>red<\/span>.<\/li>\n<\/ul>"},"evals":[],"jsHooks":[]}</script>
<!--/html_preserve-->
``` r
#2. From the Harvard sentences data, extract:

  #a. The first word from each sentence.
  #b. All words ending in ing.
str_extract(sentences, "ing$") #this doesn't apear to do anything
```

    ##   [1] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA
    ##  [24] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA
    ##  [47] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA
    ##  [70] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA
    ##  [93] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA
    ## [116] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA
    ## [139] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA
    ## [162] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA
    ## [185] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA
    ## [208] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA
    ## [231] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA
    ## [254] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA
    ## [277] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA
    ## [300] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA
    ## [323] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA
    ## [346] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA
    ## [369] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA
    ## [392] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA
    ## [415] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA
    ## [438] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA
    ## [461] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA
    ## [484] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA
    ## [507] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA
    ## [530] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA
    ## [553] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA
    ## [576] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA
    ## [599] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA
    ## [622] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA
    ## [645] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA
    ## [668] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA
    ## [691] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA
    ## [714] NA NA NA NA NA NA NA

``` r
  #c. All plurals.
# to do this I would need to find all of the words in each sentence that end with s
```

############# 14.4.4

``` r
#1. Find all words that come after a “number” like “one”, “two”, “three” etc. Pull out both the number and the word.
num<- "(one|two|three|four) ([^ ]+)"
is_num <- sentences %>%  str_subset(num)
is_num %>% str_extract(num)
```

    ##  [1] "one over"      "two met"       "two factors"   "one and"      
    ##  [5] "three lists"   "two when"      "one floor."    "one with"     
    ##  [9] "one war"       "one button"    "one in"        "one like"     
    ## [13] "two shares"    "two distinct"  "one costs"     "two pins"     
    ## [17] "four kinds"    "one rang"      "three story"   "one wall."    
    ## [21] "three inches"  "one before"    "three batches" "two leaves."

``` r
#2. Find all contractions. Separate out the pieces before and after the apostrophe. 
con <- "(can't|won't|isn't|shouldn't|wouldn't|couldn't|hasn't)" #identify the contractions
is_con <- sentences %>% str_subset(con)
is_con %>% str_extract(con) 
```

    ## character(0)

``` r
#getting a return of character (0)?

c<- "(.'.)"
is_c<- sentences %>% str_subset(c) 
is_c %>% str_extract(c) #this only gives you the letters before and after the apostrophe
```

    ##  [1] "t's" "n's" "n't" "e's" "n's" "t's" "n's" "d's" "g's" "t's" "n't"
    ## [12] "n's" "n't" "e's" "r's"

``` r
c<- "(.......'.)"
is_c<- sentences %>% str_subset(c) 
is_c %>% str_extract(c) # this is a cheap work around to the above mentioned problem
```

    ##  [1] "the man's" "but don't" "e store's" "workmen's" "the sun's"
    ##  [6] "A child's" " a king's" "a queen's" " pirate's" "eighbor's"

############# 14.4.5

``` r
#1. Replace all forward slashes in a string with backslashes.
x<- c("f/x/asd/")
#str_replace(x, c("/"="\\\\"))

#2. Implement a simple version of str_to_lower() using replace_all().
c<- c("the quick brown fox","jumped over the lazy dog")
str_replace_all(c, c("a" = "A", "b" = "B"))
```

    ## [1] "the quick Brown fox"      "jumped over the lAzy dog"

``` r
#3. Switch the first and last letters in words. Which of those strings are still words?
#sentences %>% 
  #str_replace("([^ ]+) ([^ ]+) ([^ ]+)", "\\1 \\3 \\2") #this is how the r gods switched word placement around

str_replace(words, "(.) (.) (.)", "\\1 \\3 \\2")
```

    ##   [1] "a"           "able"        "about"       "absolute"    "accept"     
    ##   [6] "account"     "achieve"     "across"      "act"         "active"     
    ##  [11] "actual"      "add"         "address"     "admit"       "advertise"  
    ##  [16] "affect"      "afford"      "after"       "afternoon"   "again"      
    ##  [21] "against"     "age"         "agent"       "ago"         "agree"      
    ##  [26] "air"         "all"         "allow"       "almost"      "along"      
    ##  [31] "already"     "alright"     "also"        "although"    "always"     
    ##  [36] "america"     "amount"      "and"         "another"     "answer"     
    ##  [41] "any"         "apart"       "apparent"    "appear"      "apply"      
    ##  [46] "appoint"     "approach"    "appropriate" "area"        "argue"      
    ##  [51] "arm"         "around"      "arrange"     "art"         "as"         
    ##  [56] "ask"         "associate"   "assume"      "at"          "attend"     
    ##  [61] "authority"   "available"   "aware"       "away"        "awful"      
    ##  [66] "baby"        "back"        "bad"         "bag"         "balance"    
    ##  [71] "ball"        "bank"        "bar"         "base"        "basis"      
    ##  [76] "be"          "bear"        "beat"        "beauty"      "because"    
    ##  [81] "become"      "bed"         "before"      "begin"       "behind"     
    ##  [86] "believe"     "benefit"     "best"        "bet"         "between"    
    ##  [91] "big"         "bill"        "birth"       "bit"         "black"      
    ##  [96] "bloke"       "blood"       "blow"        "blue"        "board"      
    ## [101] "boat"        "body"        "book"        "both"        "bother"     
    ## [106] "bottle"      "bottom"      "box"         "boy"         "break"      
    ## [111] "brief"       "brilliant"   "bring"       "britain"     "brother"    
    ## [116] "budget"      "build"       "bus"         "business"    "busy"       
    ## [121] "but"         "buy"         "by"          "cake"        "call"       
    ## [126] "can"         "car"         "card"        "care"        "carry"      
    ## [131] "case"        "cat"         "catch"       "cause"       "cent"       
    ## [136] "centre"      "certain"     "chair"       "chairman"    "chance"     
    ## [141] "change"      "chap"        "character"   "charge"      "cheap"      
    ## [146] "check"       "child"       "choice"      "choose"      "Christ"     
    ## [151] "Christmas"   "church"      "city"        "claim"       "class"      
    ## [156] "clean"       "clear"       "client"      "clock"       "close"      
    ## [161] "closes"      "clothe"      "club"        "coffee"      "cold"       
    ## [166] "colleague"   "collect"     "college"     "colour"      "come"       
    ## [171] "comment"     "commit"      "committee"   "common"      "community"  
    ## [176] "company"     "compare"     "complete"    "compute"     "concern"    
    ## [181] "condition"   "confer"      "consider"    "consult"     "contact"    
    ## [186] "continue"    "contract"    "control"     "converse"    "cook"       
    ## [191] "copy"        "corner"      "correct"     "cost"        "could"      
    ## [196] "council"     "count"       "country"     "county"      "couple"     
    ## [201] "course"      "court"       "cover"       "create"      "cross"      
    ## [206] "cup"         "current"     "cut"         "dad"         "danger"     
    ## [211] "date"        "day"         "dead"        "deal"        "dear"       
    ## [216] "debate"      "decide"      "decision"    "deep"        "definite"   
    ## [221] "degree"      "department"  "depend"      "describe"    "design"     
    ## [226] "detail"      "develop"     "die"         "difference"  "difficult"  
    ## [231] "dinner"      "direct"      "discuss"     "district"    "divide"     
    ## [236] "do"          "doctor"      "document"    "dog"         "door"       
    ## [241] "double"      "doubt"       "down"        "draw"        "dress"      
    ## [246] "drink"       "drive"       "drop"        "dry"         "due"        
    ## [251] "during"      "each"        "early"       "east"        "easy"       
    ## [256] "eat"         "economy"     "educate"     "effect"      "egg"        
    ## [261] "eight"       "either"      "elect"       "electric"    "eleven"     
    ## [266] "else"        "employ"      "encourage"   "end"         "engine"     
    ## [271] "english"     "enjoy"       "enough"      "enter"       "environment"
    ## [276] "equal"       "especial"    "europe"      "even"        "evening"    
    ## [281] "ever"        "every"       "evidence"    "exact"       "example"    
    ## [286] "except"      "excuse"      "exercise"    "exist"       "expect"     
    ## [291] "expense"     "experience"  "explain"     "express"     "extra"      
    ## [296] "eye"         "face"        "fact"        "fair"        "fall"       
    ## [301] "family"      "far"         "farm"        "fast"        "father"     
    ## [306] "favour"      "feed"        "feel"        "few"         "field"      
    ## [311] "fight"       "figure"      "file"        "fill"        "film"       
    ## [316] "final"       "finance"     "find"        "fine"        "finish"     
    ## [321] "fire"        "first"       "fish"        "fit"         "five"       
    ## [326] "flat"        "floor"       "fly"         "follow"      "food"       
    ## [331] "foot"        "for"         "force"       "forget"      "form"       
    ## [336] "fortune"     "forward"     "four"        "france"      "free"       
    ## [341] "friday"      "friend"      "from"        "front"       "full"       
    ## [346] "fun"         "function"    "fund"        "further"     "future"     
    ## [351] "game"        "garden"      "gas"         "general"     "germany"    
    ## [356] "get"         "girl"        "give"        "glass"       "go"         
    ## [361] "god"         "good"        "goodbye"     "govern"      "grand"      
    ## [366] "grant"       "great"       "green"       "ground"      "group"      
    ## [371] "grow"        "guess"       "guy"         "hair"        "half"       
    ## [376] "hall"        "hand"        "hang"        "happen"      "happy"      
    ## [381] "hard"        "hate"        "have"        "he"          "head"       
    ## [386] "health"      "hear"        "heart"       "heat"        "heavy"      
    ## [391] "hell"        "help"        "here"        "high"        "history"    
    ## [396] "hit"         "hold"        "holiday"     "home"        "honest"     
    ## [401] "hope"        "horse"       "hospital"    "hot"         "hour"       
    ## [406] "house"       "how"         "however"     "hullo"       "hundred"    
    ## [411] "husband"     "idea"        "identify"    "if"          "imagine"    
    ## [416] "important"   "improve"     "in"          "include"     "income"     
    ## [421] "increase"    "indeed"      "individual"  "industry"    "inform"     
    ## [426] "inside"      "instead"     "insure"      "interest"    "into"       
    ## [431] "introduce"   "invest"      "involve"     "issue"       "it"         
    ## [436] "item"        "jesus"       "job"         "join"        "judge"      
    ## [441] "jump"        "just"        "keep"        "key"         "kid"        
    ## [446] "kill"        "kind"        "king"        "kitchen"     "knock"      
    ## [451] "know"        "labour"      "lad"         "lady"        "land"       
    ## [456] "language"    "large"       "last"        "late"        "laugh"      
    ## [461] "law"         "lay"         "lead"        "learn"       "leave"      
    ## [466] "left"        "leg"         "less"        "let"         "letter"     
    ## [471] "level"       "lie"         "life"        "light"       "like"       
    ## [476] "likely"      "limit"       "line"        "link"        "list"       
    ## [481] "listen"      "little"      "live"        "load"        "local"      
    ## [486] "lock"        "london"      "long"        "look"        "lord"       
    ## [491] "lose"        "lot"         "love"        "low"         "luck"       
    ## [496] "lunch"       "machine"     "main"        "major"       "make"       
    ## [501] "man"         "manage"      "many"        "mark"        "market"     
    ## [506] "marry"       "match"       "matter"      "may"         "maybe"      
    ## [511] "mean"        "meaning"     "measure"     "meet"        "member"     
    ## [516] "mention"     "middle"      "might"       "mile"        "milk"       
    ## [521] "million"     "mind"        "minister"    "minus"       "minute"     
    ## [526] "miss"        "mister"      "moment"      "monday"      "money"      
    ## [531] "month"       "more"        "morning"     "most"        "mother"     
    ## [536] "motion"      "move"        "mrs"         "much"        "music"      
    ## [541] "must"        "name"        "nation"      "nature"      "near"       
    ## [546] "necessary"   "need"        "never"       "new"         "news"       
    ## [551] "next"        "nice"        "night"       "nine"        "no"         
    ## [556] "non"         "none"        "normal"      "north"       "not"        
    ## [561] "note"        "notice"      "now"         "number"      "obvious"    
    ## [566] "occasion"    "odd"         "of"          "off"         "offer"      
    ## [571] "office"      "often"       "okay"        "old"         "on"         
    ## [576] "once"        "one"         "only"        "open"        "operate"    
    ## [581] "opportunity" "oppose"      "or"          "order"       "organize"   
    ## [586] "original"    "other"       "otherwise"   "ought"       "out"        
    ## [591] "over"        "own"         "pack"        "page"        "paint"      
    ## [596] "pair"        "paper"       "paragraph"   "pardon"      "parent"     
    ## [601] "park"        "part"        "particular"  "party"       "pass"       
    ## [606] "past"        "pay"         "pence"       "pension"     "people"     
    ## [611] "per"         "percent"     "perfect"     "perhaps"     "period"     
    ## [616] "person"      "photograph"  "pick"        "picture"     "piece"      
    ## [621] "place"       "plan"        "play"        "please"      "plus"       
    ## [626] "point"       "police"      "policy"      "politic"     "poor"       
    ## [631] "position"    "positive"    "possible"    "post"        "pound"      
    ## [636] "power"       "practise"    "prepare"     "present"     "press"      
    ## [641] "pressure"    "presume"     "pretty"      "previous"    "price"      
    ## [646] "print"       "private"     "probable"    "problem"     "proceed"    
    ## [651] "process"     "produce"     "product"     "programme"   "project"    
    ## [656] "proper"      "propose"     "protect"     "provide"     "public"     
    ## [661] "pull"        "purpose"     "push"        "put"         "quality"    
    ## [666] "quarter"     "question"    "quick"       "quid"        "quiet"      
    ## [671] "quite"       "radio"       "rail"        "raise"       "range"      
    ## [676] "rate"        "rather"      "read"        "ready"       "real"       
    ## [681] "realise"     "really"      "reason"      "receive"     "recent"     
    ## [686] "reckon"      "recognize"   "recommend"   "record"      "red"        
    ## [691] "reduce"      "refer"       "regard"      "region"      "relation"   
    ## [696] "remember"    "report"      "represent"   "require"     "research"   
    ## [701] "resource"    "respect"     "responsible" "rest"        "result"     
    ## [706] "return"      "rid"         "right"       "ring"        "rise"       
    ## [711] "road"        "role"        "roll"        "room"        "round"      
    ## [716] "rule"        "run"         "safe"        "sale"        "same"       
    ## [721] "saturday"    "save"        "say"         "scheme"      "school"     
    ## [726] "science"     "score"       "scotland"    "seat"        "second"     
    ## [731] "secretary"   "section"     "secure"      "see"         "seem"       
    ## [736] "self"        "sell"        "send"        "sense"       "separate"   
    ## [741] "serious"     "serve"       "service"     "set"         "settle"     
    ## [746] "seven"       "sex"         "shall"       "share"       "she"        
    ## [751] "sheet"       "shoe"        "shoot"       "shop"        "short"      
    ## [756] "should"      "show"        "shut"        "sick"        "side"       
    ## [761] "sign"        "similar"     "simple"      "since"       "sing"       
    ## [766] "single"      "sir"         "sister"      "sit"         "site"       
    ## [771] "situate"     "six"         "size"        "sleep"       "slight"     
    ## [776] "slow"        "small"       "smoke"       "so"          "social"     
    ## [781] "society"     "some"        "son"         "soon"        "sorry"      
    ## [786] "sort"        "sound"       "south"       "space"       "speak"      
    ## [791] "special"     "specific"    "speed"       "spell"       "spend"      
    ## [796] "square"      "staff"       "stage"       "stairs"      "stand"      
    ## [801] "standard"    "start"       "state"       "station"     "stay"       
    ## [806] "step"        "stick"       "still"       "stop"        "story"      
    ## [811] "straight"    "strategy"    "street"      "strike"      "strong"     
    ## [816] "structure"   "student"     "study"       "stuff"       "stupid"     
    ## [821] "subject"     "succeed"     "such"        "sudden"      "suggest"    
    ## [826] "suit"        "summer"      "sun"         "sunday"      "supply"     
    ## [831] "support"     "suppose"     "sure"        "surprise"    "switch"     
    ## [836] "system"      "table"       "take"        "talk"        "tape"       
    ## [841] "tax"         "tea"         "teach"       "team"        "telephone"  
    ## [846] "television"  "tell"        "ten"         "tend"        "term"       
    ## [851] "terrible"    "test"        "than"        "thank"       "the"        
    ## [856] "then"        "there"       "therefore"   "they"        "thing"      
    ## [861] "think"       "thirteen"    "thirty"      "this"        "thou"       
    ## [866] "though"      "thousand"    "three"       "through"     "throw"      
    ## [871] "thursday"    "tie"         "time"        "to"          "today"      
    ## [876] "together"    "tomorrow"    "tonight"     "too"         "top"        
    ## [881] "total"       "touch"       "toward"      "town"        "trade"      
    ## [886] "traffic"     "train"       "transport"   "travel"      "treat"      
    ## [891] "tree"        "trouble"     "true"        "trust"       "try"        
    ## [896] "tuesday"     "turn"        "twelve"      "twenty"      "two"        
    ## [901] "type"        "under"       "understand"  "union"       "unit"       
    ## [906] "unite"       "university"  "unless"      "until"       "up"         
    ## [911] "upon"        "use"         "usual"       "value"       "various"    
    ## [916] "very"        "video"       "view"        "village"     "visit"      
    ## [921] "vote"        "wage"        "wait"        "walk"        "wall"       
    ## [926] "want"        "war"         "warm"        "wash"        "waste"      
    ## [931] "watch"       "water"       "way"         "we"          "wear"       
    ## [936] "wednesday"   "wee"         "week"        "weigh"       "welcome"    
    ## [941] "well"        "west"        "what"        "when"        "where"      
    ## [946] "whether"     "which"       "while"       "white"       "who"        
    ## [951] "whole"       "why"         "wide"        "wife"        "will"       
    ## [956] "win"         "wind"        "window"      "wish"        "with"       
    ## [961] "within"      "without"     "woman"       "wonder"      "wood"       
    ## [966] "word"        "work"        "world"       "worry"       "worse"      
    ## [971] "worth"       "would"       "write"       "wrong"       "year"       
    ## [976] "yes"         "yesterday"   "yet"         "you"         "young"

############# 14.4.6

``` r
#1. Split up a string like "apples, pears, and bananas" into individual components.
c<- ("apples pears bananas")
str_split(c, " ", simplify =TRUE)
```

    ##      [,1]     [,2]    [,3]     
    ## [1,] "apples" "pears" "bananas"

``` r
#2. Why is it better to split up by boundary("word") than " "?
#by splitting using a word/boundary you are being more specific to what the output object will be.

#3. What does splitting with an empty string ("") do? Experiment, and then read the documentation
str_split(c, "", simplify =TRUE)
```

    ##      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] [,13]
    ## [1,] "a"  "p"  "p"  "l"  "e"  "s"  " "  "p"  "e"  "a"   "r"   "s"   " "  
    ##      [,14] [,15] [,16] [,17] [,18] [,19] [,20]
    ## [1,] "b"   "a"   "n"   "a"   "n"   "a"   "s"

``` r
#Splitting with an empty string gives you every character, including spaces, that exist in the string
```

############# 14.5.1

1. How would you find all strings containing  with regex() vs. with fixed()?
============================================================================

fixed() is a dreamy function that match a sequence exactly. This can easily cut through all the "false" positives of using str\_detect HOWEVER, because fixed() matches directly when using non-English data certain character will be treated as non-matching because they are defined in different ways

``` r
?fixed()
a1 <- "\u00e1"
a2 <- "a\u0301"
c(a1, a2)
```

    ## [1] "á" "á"

``` r
#> [1] "á" "á"
a1 == a2
```

    ## [1] FALSE

``` r
#> [1] FALSE
str_detect(a1, fixed(a2))
```

    ## [1] FALSE

``` r
#> [1] FALSE
str_detect(a1, coll(a2)) #coll() allows for case insensitive matching
```

    ## [1] TRUE

``` r
#> [1] TRUE

a <- c("aei\\", "x\\y", "\'")
a
```

    ## [1] "aei\\" "x\\y"  "'"

``` r
#Using a regular expression:
str_detect(a, "\\\\")
```

    ## [1]  TRUE  TRUE FALSE

``` r
str_view_all(a, "\\\\")
```

<!--html_preserve-->

<script type="application/json" data-for="htmlwidget-707126abdc35016e2463">{"x":{"html":"<ul>\n  <li>aei<span class='match'>\\<\/span><\/li>\n  <li>x<span class='match'>\\<\/span>y<\/li>\n  <li>'<\/li>\n<\/ul>"},"evals":[],"jsHooks":[]}</script>
<!--/html_preserve-->
``` r
str_detect(a, fixed("\\")) #this does not work!
```

    ## [1]  TRUE  TRUE FALSE

``` r
str_detect(a, fixed("\\\\")) #this returns all falses :(
```

    ## [1] FALSE FALSE FALSE

############# 14.7.1

Notes on stringi: stringi is the "parent" to stringr, in that string is built on a subset of functions found in stringi, making it a great place for people who are new to character strings to start. \#1. Find the stringi functions that:

``` r
#install.packages("stringi")
library(stringi)
```

2. Count the number of words.
=============================

``` r
#stri_length(sentences) for each string, this is giving the number of characters in each sentence

#stri_width(sentences) 

#stri_subset(sentences, "\\b[words]\\b")
#if we just used stringr we would get:
str_count(sentences, "\\W+")
```

    ##   [1]  8  8 10  9  7  7  8  8  7  8  8  8 10  7  8  9  6  8  8  8  9  9 10
    ##  [24]  8  9  7  7  8  8  6  7  8  8  7  7  8  7  7  8  6  9  9  7  8  8  7
    ##  [47]  9  7  7  5  7  8  6  9  9  7  7  7  7  8  9  8  8  8  7  7 10 10  9
    ##  [70] 10  9  8  8  8  7  7  9  8  9  8  7  8  7  8  7  7  6  6  6  8  7  9
    ##  [93]  8  9  7  8  8  8  6  7  7  7  7  9  9  6  8  7  7  7 10  8  7  8  7
    ## [116]  7  8 10  7  7  6  9  9  7  7  8  9  9  8  7  9  7  6  7 10  7  9  8
    ## [139]  8  9  7  7  7  7  7  5  8 10 10  9  8  8  7  9  8  6  9  8  7  9 10
    ## [162]  8  8  8  8  8  8  9  7  9  6  7  8  9  6  8  7  8  9  9  6  7  7  9
    ## [185]  7  8  7  7 10  8  9  9  7  8 10  7  9  8  7  8  9  9  9  8  7  9  7
    ## [208]  8  9  8  8 10  8  6  6  7  9  8  8  9  7  9  7  8 10  8  8  7  8  7
    ## [231]  8  8  9 10  8  7  6  8  7  8 10  9  9  7  8  7  9  7  6  8  8 10  6
    ## [254]  8  7  8  7  7  7  5  8 10  9  8  6  7  7  8  7  8 10  8  8  7  9  8
    ## [277]  8  7  8  8  9  9  7  8  8  7 11  7  7  7  9  8  8  8  9  9  8  9 11
    ## [300]  7  7  9  9  6  8 10  9 10  7  8  8  8  9  8  8  9  9  5  7  7  7  8
    ## [323]  8  8 11  9  6  7  7  8  7  9  8  8  7  9  8  9  9  7 10  8 11  8  7
    ## [346]  9  8  9  9  5  9  5  9  8  9  8 10  6  7  9  7  8 10  8  9  7  7  8
    ## [369]  7  7  9  8  7  8  6  8  6  9  6  7  8  7  6  6  6  9  6  8  7  9  7
    ## [392]  7  9  9  7  8  8  6  8  7  8  7  6  8  9  8  8 10  7  7  6  7  6 10
    ## [415]  6  7  8 10 10  8  8  7  7  9  9  8  9  9  6  7  9  7  9  9  7  7  9
    ## [438]  8  6  7  8  9  7  8  6  9  8  8  8  8  7  8  9  7  8  8  8 11  9  9
    ## [461]  7  9  8  9  9  9  8  7  8  8  8  7  6  8  9  9 10  8  8  7 10  9  8
    ## [484]  8 10  8 10  7  8 11 10  9  7  8  8  9  9  6 10  8  7  7  8  9  9  6
    ## [507]  9 11  8 10  7  9  9  9  8  8  8  7  9  8  7  5  7  8  9  6  8  9  6
    ## [530]  7 10  8  8  8  8  8  8  8  8 10  7 11  7 10  9 11  8 10  6  9  7  7
    ## [553]  7  8  7 10  8 10  8  9  8  7  6  8 10  9  9  7  9  8  9  9 12 11  9
    ## [576]  8  7 10 10  8  8 10  8  7  8 10  6  8  7  6  7  8  7 10  7  7  5  9
    ## [599]  8  8  8  9 10  9  7 10  6  7  9  7  7  8  9 11  8  7  7  8  9  9  9
    ## [622] 10 10  9  9 11  9  9  6  7  8 11  9  9  8  9  9  5  6  8  8  6  8 10
    ## [645]  8  8  8  8  8  8  8  9  8  8 11  9  9  9 10  7  5  8  7 10  9  8  8
    ## [668] 10  8  8  7 10  7  7  7  7  7  9  8  9  9  7  6  8  9  8  9  8  7  8
    ## [691]  9 12  8  9  9  9  9  8  9 11  7  7  8  6  8  8  8  8  8  7  8  7  9
    ## [714]  9  6  8  7  7  6  7

``` r
str_count(sentences, "\\S+")
```

    ##   [1]  8  8  9  9  7  7  8  8  7  8  8  8 10  7  8  9  6  7  8  8  9  9 10
    ##  [24]  8  9  7  7  8  8  6  7  8  8  7  7  8  7  7  8  6  9  9  7  8  8  7
    ##  [47]  9  7  7  5  7  8  6  9  9  7  7  7  7  8  9  8  8  8  7  7 10 10  9
    ##  [70] 10  9  8  8  8  7  7  9  8  9  8  7  8  7  8  7  7  6  6  6  8  7  9
    ##  [93]  8  9  7  8  8  8  6  7  7  7  7  8  9  6  8  7  7  7 10  8  7  8  7
    ## [116]  7  8 10  7  7  6  9  9  7  7  8  9  9  8  7  9  7  6  7 10  7  9  8
    ## [139]  8  9  7  7  7  7  7  5  8 10 10  9  8  8  7  9  8  6  9  8  7  9 10
    ## [162]  8  8  8  8  8  8  9  7  9  6  7  8  9  6  8  7  8  9  8  6  7  7  9
    ## [185]  7  8  7  7 10  8  8  9  7  8 10  7  9  8  7  8  9  9  9  8  7  9  7
    ## [208]  8  9  8  8 10  8  6  6  7  9  8  8  9  7  9  7  8 10  8  8  7  8  7
    ## [231]  8  8  9 10  8  7  6  8  7  8 10  9 10  7  8  7  9  7  6  8  8 10  6
    ## [254]  8  7  8  7  7  7  5  8 10  9  8  6  7  7  8  7  7 10  8  8  7  9  8
    ## [277]  8  7  8  8  9  9  7  8  8  7 11  7  7  7  9  8  8  8  9  9  8  9 11
    ## [300]  7  7  9  8  6  8 10  9  9  7  8  8  8  9  8  8  9  9  5  7  7  7  8
    ## [323]  8  8 11  8  6  7  7  8  7  9  8  8  7  9  8  9  9  7 10  8 11  8  7
    ## [346]  9  8  8  9  5  9  5  9  8  9  8  9  6  7  9  7  8 10  8  9  7  7  8
    ## [369]  7  7  9  8  7  8  6  8  6  9  6  7  8  7  6  6  6  9  6  8  7  9  7
    ## [392]  7  8  9  7  8  8  6  8  7  8  7  6  8  9  8  8 10  7  7  6  7  6 10
    ## [415]  6  7  8 10 10  8  8  7  7  9  9  8  9  8  6  7  9  7  9  9  7  7  9
    ## [438]  8  6  7  8  9  7  8  6  9  8  8  8  8  7  8  9  7  8  8  8 11  9  9
    ## [461]  7  9  8  9  9  9  8  7  8  8  8  7  6  8  9  9  9  8  8  7 10  9  8
    ## [484]  8 10  8 10  7  8 11 10  9  7  8  8  9  9  6 10  8  7  7  8  9  9  6
    ## [507]  9 11  8 10  7  9  8  9  8  8  8  7  9  8  7  5  7  8  9  6  8  9  6
    ## [530]  7 10  8  8  8  8  7  8  8  8 10  7 11  7 10  9 11  8 10  6  9  7  7
    ## [553]  7  8  7 10  8 10  8  9  8  7  6  8 10  9  9  7  9  8  9  9 12 11  9
    ## [576]  8  7 10 10  8  8 10  8  7  8 10  6  8  7  6  7  8  7 10  7  7  5  9
    ## [599]  8  8  8  9 10  9  7 10  6  7  9  7  7  8  9 11  8  7  7  8  9  9  9
    ## [622] 10 10  8  9 11  9  9  6  7  8 11  9  9  8  8  9  5  6  8  8  6  8 10
    ## [645]  8  8  8  8  8  8  8  9  8  8 11  9  9  9  9  7  5  8  7 10  9  8  8
    ## [668] 10  8  8  7 10  7  7  7  7  7  8  8  8  9  7  6  8  9  8  9  8  7  8
    ## [691]  9 12  8  9  9  9  9  8  9 11  7  7  8  6  8  8  8  8  8  7  8  7  8
    ## [714]  9  6  8  7  7  6  7

``` r
#for some reason adapting str_count to stri_count is not synonymous
```

``` r
#This is a great way to genearte a random password!
stri_rand_strings(5,5, '[A-Z]')
```

    ## Warning in stri_rand_strings(5, 5, "[A-Z]"): '.Random.seed' is not an
    ## integer vector but of type 'NULL', so ignored

    ## [1] "BDXVC" "JRSHN" "QVTCV" "WYMXU" "VPKFY"

``` r
#stri_rand_strings(x,y, 'matching') where x = number of strings, y = number of characters per string.
stri_rand_strings(5,4, c('[A-Z]','[1-9]'))
```

    ## Warning in stri_rand_strings(5, 4, c("[A-Z]", "[1-9]")): vector length not
    ## consistent with other arguments

    ## [1] "PIHB" "8155" "AJWM" "3213" "FQFD"

``` r
#R does not like this because the vector length is not the same as the arguments...
```

Part I reflection:
==================

This exercise took me SO many hours to complete and many of the problems I attempted I have no resolution despite trolling the internet for solutions. I find much of the matching syntax to be not very intuitive, especially with \\ and ordering and spent A LOT of time trying to figure that out alone. A great resource I found: <http://www2.stat.duke.edu/~cr173/Sta523_Fa15/regex.html>

PART 2
------

Create a function using the gapminder data

``` r
#library(tidyverse)
#install.packages("gapminder")
library(gapminder)
#First, explore what we're working with in the data:
gap<-gapminder
str(gap) #6 variables, 1704 observations
```

    ## Classes 'tbl_df', 'tbl' and 'data.frame':    1704 obs. of  6 variables:
    ##  $ country  : Factor w/ 142 levels "Afghanistan",..: 1 1 1 1 1 1 1 1 1 1 ...
    ##  $ continent: Factor w/ 5 levels "Africa","Americas",..: 3 3 3 3 3 3 3 3 3 3 ...
    ##  $ year     : int  1952 1957 1962 1967 1972 1977 1982 1987 1992 1997 ...
    ##  $ lifeExp  : num  28.8 30.3 32 34 36.1 ...
    ##  $ pop      : int  8425333 9240934 10267083 11537966 13079460 14880372 12881816 13867957 16317921 22227415 ...
    ##  $ gdpPercap: num  779 821 853 836 740 ...

``` r
#What do I want my function to do? I want to easily build a linear model looking for countries comparing different predictor variables.
#in the most rudimentary, this is what I want my function to do:
gap %>% filter(country =="Canada") #highlight 1 country
```

    ## # A tibble: 12 x 6
    ##    country continent  year lifeExp      pop gdpPercap
    ##     <fctr>    <fctr> <int>   <dbl>    <int>     <dbl>
    ##  1  Canada  Americas  1952  68.750 14785584  11367.16
    ##  2  Canada  Americas  1957  69.960 17010154  12489.95
    ##  3  Canada  Americas  1962  71.300 18985849  13462.49
    ##  4  Canada  Americas  1967  72.130 20819767  16076.59
    ##  5  Canada  Americas  1972  72.880 22284500  18970.57
    ##  6  Canada  Americas  1977  74.210 23796400  22090.88
    ##  7  Canada  Americas  1982  75.760 25201900  22898.79
    ##  8  Canada  Americas  1987  76.860 26549700  26626.52
    ##  9  Canada  Americas  1992  77.950 28523502  26342.88
    ## 10  Canada  Americas  1997  78.610 30305843  28954.93
    ## 11  Canada  Americas  2002  79.770 31902268  33328.97
    ## 12  Canada  Americas  2007  80.653 33390141  36319.24

``` r
panel <-gap %>% filter(country =="Canada") %>% select(country, lifeExp, pop) #data is grouped by year for canada, we have mean life expectancy and mean population 
lm(panel$lifeExp~panel$pop)
```

    ## 
    ## Call:
    ## lm(formula = panel$lifeExp ~ panel$pop)
    ## 
    ## Coefficients:
    ## (Intercept)    panel$pop  
    ##   5.868e+01    6.630e-07

``` r
#This following type of function will be important for my own analysis where I will be plugging different datasets with the same variables into a lm and not wanting to rewrite the skeleton code:


model_funs<- function(x,y){
  pain<- x %>% filter(country == y) %>% select(country, lifeExp, pop)
  lmodel<-lm(pain$lifeExp~panel$pop)
  print(lmodel)
  lm.sum<-summary(lmodel)
  print(lm.sum)}
#It would be really nice to stop this code, or get a warning if 
#the model was not significant, that is the p-Value was greater than 0.05

#What if I try to add the summary statistics to the dataset so it is wrapped up all nicely?
#model_funsB<- function(x,y){
 # pain<- x %>% filter(country == y) %>% select(country, lifeExp, pop)
  #lmodel<-lm(pain$lifeExp~panel$pop)
  #print(lmodel)
  #lm.sum<-summary(lmodel)
  #print(lm.sum)
  #xstats <- x %>% mutate("yhat"=fitted(lmodel), "x$resid"=resid(lmodel), #"x$stdev"=resid(lmodel)/lm.sum$sigma)} 


#test:
(model_funs(gap, "Algeria"))
```

    ## 
    ## Call:
    ## lm(formula = pain$lifeExp ~ panel$pop)
    ## 
    ## Coefficients:
    ## (Intercept)    panel$pop  
    ##   1.689e+01    1.723e-06  
    ## 
    ## 
    ## Call:
    ## lm(formula = pain$lifeExp ~ panel$pop)
    ## 
    ## Residuals:
    ##     Min      1Q  Median      3Q     Max 
    ## -2.1065 -0.9611 -0.2251  0.8036  3.1744 
    ## 
    ## Coefficients:
    ##              Estimate Std. Error t value Pr(>|t|)    
    ## (Intercept) 1.689e+01  1.982e+00   8.521 6.74e-06 ***
    ## panel$pop   1.723e-06  7.893e-08  21.825 9.13e-10 ***
    ## ---
    ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
    ## 
    ## Residual standard error: 1.555 on 10 degrees of freedom
    ## Multiple R-squared:  0.9794, Adjusted R-squared:  0.9774 
    ## F-statistic: 476.3 on 1 and 10 DF,  p-value: 9.126e-10

    ## 
    ## Call:
    ## lm(formula = pain$lifeExp ~ panel$pop)
    ## 
    ## Residuals:
    ##     Min      1Q  Median      3Q     Max 
    ## -2.1065 -0.9611 -0.2251  0.8036  3.1744 
    ## 
    ## Coefficients:
    ##              Estimate Std. Error t value Pr(>|t|)    
    ## (Intercept) 1.689e+01  1.982e+00   8.521 6.74e-06 ***
    ## panel$pop   1.723e-06  7.893e-08  21.825 9.13e-10 ***
    ## ---
    ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
    ## 
    ## Residual standard error: 1.555 on 10 degrees of freedom
    ## Multiple R-squared:  0.9794, Adjusted R-squared:  0.9774 
    ## F-statistic: 476.3 on 1 and 10 DF,  p-value: 9.126e-10

``` r
#(model_funsB(gap, "Canada"))#hmmm something about the yhats not being the same length as the input variable...possibly some NA's in there?

#Oh no! What if the data doesn't appear linear? Easy, 
#plop those transformations right into the code!
model_nln<- function(x,y){
  pain<- x %>% filter(country == y) %>% select(country, lifeExp, pop)
  lmodel<-lm(pain$lifeExp~(panel$pop^2))
  print(lmodel)
  lm.sum<-summary(lmodel)
  print(lm.sum)
}

model_nln(gap, "Algeria")
```

    ## 
    ## Call:
    ## lm(formula = pain$lifeExp ~ (panel$pop^2))
    ## 
    ## Coefficients:
    ## (Intercept)    panel$pop  
    ##   1.689e+01    1.723e-06  
    ## 
    ## 
    ## Call:
    ## lm(formula = pain$lifeExp ~ (panel$pop^2))
    ## 
    ## Residuals:
    ##     Min      1Q  Median      3Q     Max 
    ## -2.1065 -0.9611 -0.2251  0.8036  3.1744 
    ## 
    ## Coefficients:
    ##              Estimate Std. Error t value Pr(>|t|)    
    ## (Intercept) 1.689e+01  1.982e+00   8.521 6.74e-06 ***
    ## panel$pop   1.723e-06  7.893e-08  21.825 9.13e-10 ***
    ## ---
    ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
    ## 
    ## Residual standard error: 1.555 on 10 degrees of freedom
    ## Multiple R-squared:  0.9794, Adjusted R-squared:  0.9774 
    ## F-statistic: 476.3 on 1 and 10 DF,  p-value: 9.126e-10

``` r
#now I have two functions for linear regressions that take care 
#if the data are linear 
#or non-linear and they automatically spit out the 
#summary statistics.

#Is there a way to get the plotting to also be 
#made more efficient?
```

``` r
#Here is a series of examples that show the utility of 
#functions in prepping a dataset for analysis:

#as_fa <- function(x) {
  #x$year.f <- as.function(x$year)
  #x$pop.f <- as.function(x$pop)} R does not like this format 

#This type of function is slightly unrealistic for gapminder data but 
#I developed it to be used in my own data where I have several 
#datasets with variables such as site, transect and plot that R would 
#like to treat as numeric or integer but for analysis I will need 
#to be factors:
as_fa <- function(x) {
  a <- x %>% mutate("year.f"=as.factor(x$year), "pop.f"=as.factor(x$pop))
  }

funsies<-as_fa(gap)
str(funsies) 
```

    ## Classes 'tbl_df', 'tbl' and 'data.frame':    1704 obs. of  8 variables:
    ##  $ country  : Factor w/ 142 levels "Afghanistan",..: 1 1 1 1 1 1 1 1 1 1 ...
    ##  $ continent: Factor w/ 5 levels "Africa","Americas",..: 3 3 3 3 3 3 3 3 3 3 ...
    ##  $ year     : int  1952 1957 1962 1967 1972 1977 1982 1987 1992 1997 ...
    ##  $ lifeExp  : num  28.8 30.3 32 34 36.1 ...
    ##  $ pop      : int  8425333 9240934 10267083 11537966 13079460 14880372 12881816 13867957 16317921 22227415 ...
    ##  $ gdpPercap: num  779 821 853 836 740 ...
    ##  $ year.f   : Factor w/ 12 levels "1952","1957",..: 1 2 3 4 5 6 7 8 9 10 ...
    ##  $ pop.f    : Factor w/ 1704 levels "60011","61325",..: 943 999 1067 1129 1169 1208 1161 1181 1229 1317 ...

``` r
#View(funsies)

#This is what the function looks like once I modified it 
#for use in my own dataset:
as_fa2<-function(x) {
  s <- x %>% mutate("site.f"=as.factor(x$site))
  t <- s %>% mutate("transect.f"=as.factor(x$transect))
  p <- t %>% mutate("plot.f"=as.factor(x$plot))
}

#but the above is an inefficient way to write the code making 
#seperate iterations for each mutate function, instead a more 
#linear approach is desirable:
as_fa3<-function(x) {
  s <- x %>% mutate("site.f"=as.factor(x$site),"transect.f"=as.factor(x$transect), "plot.f"=as.factor(x$plot))
}
```

For reference, this is what my code looked like before building a function for this homework:

``` r
#colldat$site.f<- as.factor(colldat$site)
#colldat$transect.f <- as.factor(colldat$transect)
#colldat$plot.f <- as.factor(colldat$plot)
#plotdens$site.f <- (as.factor(plotdens$site))
#plotdens$transect.f <- (as.factor(plotdens$transect))
#plotdens$plot.f <- (as.factor(plotdens$plot))
#site_info$site.f <- as.factor(site_info$site)
#site_info$transect.f <- as.factor(site_info$transect)

#This is a lesson in efficiency, I just took 8 lines of discrete code and streamlined them into a function that I can use once on each of my 3 datasets.
```

``` r
#I also need each plot to have a unique identifier so when I join different datasets, i.e. my plant and insect data, each row is properly matched up, that means adding a new column to each dataset:
un_id<- function(x){
  a<-x %>% mutate("plot_id"=as.factor(paste(site.f, transect.f, plot.f, sep= "."), "transect_id"=as.factor(paste(site.f,transect.f, sep="."))))
}
```

This is what my old code looked like for creating unique identifiers:

``` r
#colldat$plot_id <- as.factor(paste(colldat$site, colldat$transect.f, colldat$plot.f, sep= "."))
#colldat$transect_id<- as.factor(paste(colldat$site, colldat$transect.f, sep = "."))
#plotdens$plot_id <- as.factor(paste(plotdens$site, plotdens$transect.f, plotdens$plot.f, sep= "."))
#plotdens$transect_id <- as.factor(paste(plotdens$site, plotdens$transect.f,  sep= "."))
#site_info$transect_id <- as.factor(paste(site_info$site.f, site_info$transect.f, sep ="."))
```

Part II reflection:
===================

Wow this part of the assignment was SO enjoyable! Functions, while intimidating, are an excellent way to streamline a task, for instance when trying to fit linear models. I can use this type of function quite readily to determine 1. if my models are significant and 2. which variables are significant. As I continue to develop my skills I would like to be able to implement a warning that one or both of these things are false. The skeleton code that I created above can easily be changed to accomodate different, or additional, variables. It also makes performing transformations quite seamless.

Additionally I modified existing code I have been copying and pasting repeatedly in my own data analysis to build functions I can quickly plug my data into without so much redundancy. In this way functions were used to streamline much of the work I have already done in the preliminary analysis of my MSc. This is rather exciting because prior to taking this course I had a suspicion there was a much cleaner way to write this code, I was just unsure how to do it!
